{"pages":[{"title":"关于我","text":"经过一年的积累，我现在也来到了帝都来工作，目前在以太创服工作，架构组php开发工程师一枚，目前加速积累速度，也在不断学习探索最新的知识，为架构师方向努力。 扫描下方加我的微信与我0距离","link":"/about/index.html"},{"title":"反馈专区","text":"欢迎大家在这里给我反馈，我非常的感谢你们的支持！","link":"/feedback/index.html"},{"title":"友情链接","text":"暂时还没有，哈哈哈","link":"/links/index.html"}],"posts":[{"title":"Java面试题精选(第一卷)","text":"1.什么是Java虚拟机？为什么Java被称作是“平台无关的编程语言”？ 答： Java虚拟机是一个可以执行Java字节码的虚拟机进程。Java源文件被编译成能被Java虚拟机执行的字节码文件。Java被设计成允许应用程序可以运行在任意的平台，而不需要程序员为每一个平台单独重写或者是重新编译。Java虚拟机让这个变为可能，因为它知道底层硬件平台的指令长度和其他特性 2.JDK和JRE的区别是什么？ 答： Java运行时环境(JRE)是将要执行Java程序的Java虚拟机。它同时也包含了执行applet需要的浏览器插件。Java开发工具包(JDK)是完整的Java软件开发包，包含了JRE，编译器和其他的工具(比如：JavaDoc，Java调试器)，可以让开发者开发、编译、执行Java应用程序。 3.”static”关键字是什么意思？Java中是否可以覆盖(override)一个private或者是static的方法？ 答： “static”关键字表明一个成员变量或者是成员方法可以在没有所属的类的实例变量的情况下被访问。Java中static方法不能被覆盖，因为方法覆盖是基于运行时动态绑定的，而static方法是编译时静态绑定的。static方法跟类的任何实例都不相关，所以概念上不适用。 4.是否可以在static环境中访问非static变量？ 答：静态的不可以访问非静态的，但是非静态的可以访问静态变量static变量在Java中是属于类的，它在所有的实例中的值是一样的。当类被Java虚拟机载入的时候，会对static变量进行初始化。如果你的代码尝试不用实例来访问非static的变量，编译器会报错，因为这些变量还没有被创建出来，还没有跟任何实例关联上。 5.Java支持的数据类型有哪些？什么是自动拆装箱？ 答：Java语言支持的8种基本数据类型是：byteshortintlongfloatdoublebooleanchar自动装箱是Java编译器在基本数据类型和对应的对象包装类型之间做的一个转化。比如：把int转化成Integer，double转化成Double，等等。反之就是自动拆箱。 6.Java中的方法覆盖(Overriding)和方法重载(Overloading)是什么意思？ 答：Java中的方法重载发生在同一个类里面两个或者是多个方法的方法名相同但是参数不同的情况。与此相对，方法覆盖是说子类重新定义了父类的方法。 方法覆盖必须有相同的方法名，参数列表和返回类型。覆盖者可能不会限制它所覆盖的方法的访问。 7.Java中，什么是构造函数？什么是构造函数重载？什么是复制构造函数？ 答：当新对象被创建的时候，构造函数会被调用。每一个类都有构造函数。在程序员没有给类提供构造函数的情况下，Java编译器会为这个类创建一个默认的构造函数。Java中构造函数重载和方法重载很相似。可以为一个类创建多个构造函数。每一个构造函数必须有它自己唯一的参数列表。Java不支持像C++中那样的复制构造函数，这个不同点是因为如果你不自己写构造函数的情况下，Java不会创建默认的复制构造函数。 8.Java支持多继承么？ 答：ava中类不支持多继承，只支持单继承（即一个类只有一个父类）。但是java中的接口支持多继承，即一个子接口可以有多个父接口。（接口的作用是用来扩展对象的功能，一个子接口继承多个父接口，说明子接口扩展了多个功能，当类实现接口时，类就扩展了相应的功能）。 9.接口和抽象类的区别是什么？ 答：Java提供和支持创建抽象类和接口。它们的实现有共同点，不同点在于：接口中所有的方法隐含的都是抽象的。而抽象类则可以同时包含抽象和非抽象的方法。类可以实现很多个接口，但是只能继承一个抽象类类可以不实现抽象类和接口声明的所有方法，当然，在这种情况下，类也必须得声明成是抽象的。抽象类可以在不提供接口方法实现的情况下实现接口。Java接口中声明的变量默认都是final的。抽象类可以包含非final的变量。Java接口中的成员函数默认是public的。抽象类的成员函数可以是private，protected或者是public。接口是绝对抽象的，不可以被实例化。抽象类也不可以被实例化，但是，如果它包含main方法的话是可以被调用的。 10.什么是值传递和引用传递？ 答：值传递是对基本型变量而言的,传递的是该变量的一个副本,改变副本不影响原变量.引用传递一般是对于对象型变量而言的,传递的是该对象地址的一个副本, 并不是原对象本身 。 所以对引用对象进行操作会同时改变原对象.一般认为,java内的传递都是值传递. 感谢牛客网提供的面试题 详情请访问: 【牛客网Java面试题】","link":"/2017/02/12/2017-02-12-Java%E9%9D%A2%E8%AF%95%E9%A2%98%E7%B2%BE%E9%80%89-%E7%AC%AC%E4%B8%80%E5%8D%B7/"},{"title":"Java面试题精选（第二卷）","text":"进程和线程的区别是什么？ 答：进程是执行着的应用程序，而线程是进程内部的一个执行序列。一个进程可以有多个线程。线程又叫做轻量级进程。 创建线程有几种不同的方式？你喜欢哪一种？为什么？ 答： 有三种方式可以用来创建线程：1.继承Thread类2.实现Runnable接口3.应用程序可以使用Executor框架来创建线程池实现Runnable接口这种方式更受欢迎，因为这不需要继承Thread类。在应用设计中已经继承了别的对象的情况下，这需要多继承（而Java不支持多继承），只能实现接口。同时，线程池也是非常高效的，很容易实现和使用。 3.概括的解释下线程的几种可用状态。 答： 新建( new )：新创建了一个线程对象。 可运行( runnable )：线程对象创建后，其他线程(比如 main 线程）调用了该对象 的 start ()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获 取 cpu 的使用权 。 运行( running )：可运行状态( runnable )的线程获得了 cpu 时间片（ timeslice ） ，执行程序代码。 阻塞( block )：阻塞状态是指线程因为某种原因放弃了 cpu 使用权，也即让出了 cpu timeslice ，暂时停止运行。直到线程进入可运行( runnable )状态，才有 机会再次获得 cpu timeslice 转到运行( running )状态。阻塞的情况分三种： (一). 等待阻塞：运行( running )的线程执行 o . wait ()方法， JVM 会把该线程放 入等待队列( &gt;&gt;waitting queue )中。(二). 同步阻塞：运行( running )的线程在获取对象的同步锁时，若该同步锁 被别的线程占用，则 JVM 会把该线程放入锁池( lock pool )中。(三). 其他阻塞: 运行( running )的线程执行 Thread . sleep ( long ms )或 t . join ()方法，或者发出了 I / O 请求时， JVM 会把该线程置为阻塞状态。 当 sleep ()状态超时、 join ()等待线程终止或者超时、或者 I / O 处理完毕时，线程重新转入可运行( runnable )状态。 死亡( dead )：线程 run ()、 main () 方法执行结束，或者因异常退出了 run ()方法，则该线程结束生命周期。死亡的线程不可再次复生 4.同步方法和同步代码块的区别是什么？ 答：区别：同步方法默认用this或者当前类class对象作为锁；同步代码块可以选择以什么来加锁，比同步方法要更细颗粒度，我们可以选择只同步会发生同步问题的部分代码而不是整个方法. 5.在监视器(Monitor)内部，是如何做线程同步的？程序应该做哪种级别的同步？ 答： 监视器和锁在Java虚拟机中是一块使用的。监视器监视一块同步代码块，确保一次只有一个线程执行同步代码块。每一个监视器都和一个对象引用相关联。线程在获取锁之前不允许执行同步代码。 6.什么是死锁(deadlock)？ 答：两个线程或两个以上线程都在等待对方执行完毕才能继续往下执行的时候就发生了死锁。结果就是这些线程都陷入了无限的等待中。 7.如何确保N个线程可以访问N个资源同时又不导致死锁？ 答：使用多线程的时候，一种非常简单的避免死锁的方式就是：指定获取锁的顺序，并强制线程按照指定的顺序获取锁。因此，如果所有的线程都是以同样的顺序加锁和释放锁，就不会出现死锁了。 8.Java集合类框架的基本接口有哪些？ 答:集合类接口指定了一组叫做元素的对象。集合类接口的每一种具体的实现类都可以选择以它自己的方式对元素进行保存和排序。有的集合类允许重复的键，有些不允许。Java集合类提供了一套设计良好的支持对一组对象进行操作的接口和类。Java集合类里面最基本的接口有： 1.Collection：代表一组对象，每一个对象都是它的子元素。2.Set：不包含重复元素的Collection。3.List：有顺序的collection，并且可以包含重复元素。4.Map：可以把键(key)映射到值(value)的对象，键不能重复。 9.为什么集合类没有实现Cloneable和Serializable接口？ 答:克隆(cloning)或者是序列化(serialization)的语义和含义是跟具体的实现相关的。因此，应该由集合类的具体实现来决定如何被克隆或者是序列化。 10.什么是迭代器(Iterator)？ 答:Iterator接口提供了很多对集合元素进行迭代的方法。每一个集合类都包含了可以返回迭代器实例的迭代方法。迭代器可以在迭代的过程中删除底层集合的元素,但是不可以直接调用集合的remove(Object Obj)删除，可以通过迭代器的remove()方法删除。","link":"/2017/02/12/2017-02-12-Java%E9%9D%A2%E8%AF%95%E9%A2%98%E7%B2%BE%E9%80%89%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%8D%B7%EF%BC%89/"},{"title":"Java中的知识点（区别）","text":"1.public ,private, protected 不写时候的区别: 作用于 当前类 同包 子孙类 其他package public √ √ √ √ protected √ √ √ × friendly √ √ × × private √ × × × 不写时默认为friendly 2.Collection和Collections的区别 答：1.java.util.Collection是一个集合接口。它提供了集合对象进行基本操作的通用接口方法。Collection接口在java类库中有很多具体的实现。Collection接口意义是为各种具体的集合提供了最大化的统一操作方式。 1234567Collection ├List │├LinkedList │├ArrayList │└Vector │ └Stack └Set java.util.Collections是一个包装类。它包含有各种有关集合操作的静态多态方法。此类不能实例化,就像一各工具类，服务于java的Collection框架 123456789101112131415161718import java.util.ArrayList;import java.util.Collections;import java.util.List;public class TestCollections { public static void main(String args[]) { //注意List是实现Collection接口的 List list = new ArrayList(); double array[] = { 112, 111, 23, 456, 231 }; for (int i = 0; i &lt; array.length; i++) { list.add(new Double(array[i])); } Collections.sort(list); for (int i = 0; i &lt; array.length; i++) { System.out.println(list.get(i)); } // 结果：23.0 111.0 112.0 231.0 456.0 }} 3.Vector类和ArrayList类的区别 答：Vector和ArrayList同属于List接口下,Vector从java1开始一直沿用至今，他俩的最大区别之处是加入了同步锁的策略，Vector是一种老的动态数组，是线程同步的，效率很低，一般不赞成使用。 4.String和StringBuffer的区别 答:String 类代表字符串。Java 程序中的所有字符串字面值（如 “abc” ）都作为此类的实例实现。我们查看内部源码 12public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence {...} 查看源码的关键字’final’内部则是维护一个不可改变的数组，所以不可以动态的扩种添加，只能创建一个更大的对象来装载新添加的数据 下面我们来看一下’StringBuffer’的官方源代码 123456789public final class StringBuffer extends AbstractStringBuilder implements java.io.Serializable, Appendable, CharSequence{ public StringBuffer(String str) { super(str.length() + 16); append(str); }} 从这里看出我们实际上增加字符串的过程实际上就是调用了自身的append方法而已，追查具体的实现 12345678public AbstractStringBuilder append(String str) { if (str == null) str = &quot;null&quot;; int len = str.length(); ensureCapacityInternal(count + len); str.getCharsNoCheck(0, len, value, count); count += len; return this; } 实际上是计算当前字符串的长度，并且通过计数器把最新存储的位置保存下来，之前还需要判空,ensureCapacityInternal(count + len);就是他们的动态扩展数组大小的具体实现，其原理就是判断当前存储的的位数是否足够，不够就动态的空中。","link":"/2017/02/13/2017-02-13-Java%E4%B8%AD%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%88%E5%8C%BA%E5%88%AB%EF%BC%89/"},{"title":"安卓开源库推荐","text":"博主在这里记录一些特别的好的开源框架以供以后去使用,会不断的更新 1. Android-skin-supportAndroid-skin-support: 一款用心去做的Android 换肤框架, 极低的学习成本, 极好的用户体验. 只需要两行代码, 就可以实现换肤, 你值得拥有!!!开源库地址：点我查看 效果图： 2. StatefulLayoutAndroid布局，以显示最常见的状态模板，如加载，空，错误等。要做到这一点，所有你需要的是包装目标区域（视图）与StatefulLayout。开源库地址：【点击此处进入】 效果图： 3. CircleMenu这是一个效果非常棒的弹出式菜单开源库。开源库地址：【开此进入】 效果图： 4.AcesoAceso是基于Instant Run Hot Swap的Android热修复方案，使用它你能在不用重新发布版本的情况下对线上app的bug进行修复。开源库地址:【点此进入】 5. ExpectAnim一个让你的页面动起来的开源库开源库地址:【点此进入】 效果图： 6 .Snacky此款开源库能够帮你快速的建立Snackbar开源库地址:【点此进入】 效果图: 7. Zoomy Zoomy是一个简易的从缩放到撮合的安卓库 开源库地址:【点此进入】 效果图: 8. vlayout VirtualLayout是一个针对RecyclerView的LayoutManager扩展, 主要提供一整套布局方案和布局间的组件复用的问题。 开源库地址：【点此进入】 效果图:","link":"/2017/03/01/2017-03-01-%E5%AE%89%E5%8D%93%E5%BC%80%E6%BA%90%E5%BA%93%E6%8E%A8%E8%8D%90/"},{"title":"经典安卓面试题","text":"1. Activity生命周期 这个是安卓中的基础，重要性想必不用我说了吧，如果还有对此不太了解的要回去好好复习了哦现在主要考的还是对于他们生命周期的灵活运用 2. Service生命周期 注意：Service两种启动方式,startService()和bindService()，还有混合启动的概念 答： 给一个图足以说明生命周期的概念: 3. 理解Activity，View,Window三者关系 这个问题真的很不好回答。所以这里先来个算是比较恰当的比喻来形容下它们的关系吧。 Activity像一个工匠（控制单元） Window像窗户（承载模型） View像窗花（显示视图）LayoutInflater像剪刀，Xml配置像窗花图纸。 答： 1. Activity构造的时候会初始化一个Window，准确的说是PhoneWindow。 2. 这个PhoneWindow有一个“ViewRoot”，这个“ViewRoot”是一个View或者说ViewGroup，是最初始的根视图。 3. “ViewRoot”通过addView方法来一个个的添加View。比如TextView，Button等 4. 这些View的事件监听，是由WindowManagerService来接受消息，并且回调Activity函数。比如onClickListener，onKeyDown等。 4. 四种LaunchMode及其使用场景答： standard 模式这是默认模式，每次激活Activity时都会创建Activity实例，并放入任务栈中。使用场景：大多数Activity。 singleTop 模式如果在任务的栈顶正好存在该Activity的实例，就重用该实例( 会调用实例的 onNewIntent() )，否则就会创建新的实例并放入栈顶，即使栈中已经存在该Activity的实例，只要不在栈顶，都会创建新的实例。使用场景如新闻类或者阅读类App的内容页面。 singleTask 模式如果在栈中已经有该Activity的实例，就重用该实例(会调用实例的 onNewIntent() )。重用时，会让该实例回到栈顶，因此在它上面的实例将会被移出栈。如果栈中不存在该实例，将会创建新的实例放入栈中。使用场景如浏览器的主界面。不管从多少个应用启动浏览器，只会启动主界面一次，其余情况都会走onNewIntent，并且会清空主界面上面的其他页面。 singleInstance 模式在一个新栈中创建该Activity的实例，并让多个应用共享该栈中的该Activity实例。一旦该模式的Activity实例已经存在于某个栈中，任何应用再激活该Activity时都会重用该栈中的实例( 会调用实例的 onNewIntent() )。其效果相当于多个应用共享一个应用，不管谁激活该 Activity 都会进入同一个应用中。使用场景如闹铃提醒，将闹铃提醒与闹铃设置分离。singleInstance不要用于中间页面，如果用于中间页面，跳转会有问题，比如：A -&gt; B (singleInstance) -&gt; C，完全退出后，在此启动，首先打开的是B。 5. View的绘制流程 这个就比较复杂了，我老师说过这个东西每个两年玩不明白，可见这个东西的复杂性三大过程：measure过程，layout过程，draw过程 答： 6. Touch事件传递机制答： 12345678public boolean dispatchTouchEvent(MotionEventev); //用来分派eventpublic boolean onInterceptTouchEvent(MotionEventev);//用来拦截eventpublic boolean onTouchEvent(MotionEventev);//用来处理event 其中Activity和View控件（TextView）拥有分派和处理事件方法，View容器（LinearLayout）具有分派，拦截，处理事件方法。这里也有个比喻：领导都会把任务向下分派，一旦下面的人把事情做不好，就不会再把后续的任务交给下面的人来做了，只能自己亲自做，如果自己也做不了，就只能告诉上级不能完成任务，上级又会重复他的过程。另外，领导都有权利拦截任务，对下级隐瞒该任务，而直接自己去做，如果做不成，也只能向上级报告不能完成任务。 7. Android中的几种动画答:曾被问到Android中有几种动画，这个问题也好难回答。Android3.0之前有2种，3.0后有3种。 FrameAnimation（逐帧动画）：将多张图片组合起来进行播放，类似于早期电影的工作原理，很多App的loading是采用这种方式。 TweenAnimation（补间动画）：是对某个View进行一系列的动画的操作，包括淡入淡出（Alpha），缩放（Scale），平移（Translate），旋转（Rotate）四种模式。 PropertyAnimation（属性动画）：属性动画不再仅仅是一种视觉效果了，而是一种不断地对值进行操作的机制，并将值赋到指定对象的指定属性上，可以是任意对象的任意属性。 8. Android中跨进程通讯的几种方式","link":"/2017/03/05/2017-03-05-%E7%BB%8F%E5%85%B8%E5%AE%89%E5%8D%93%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"title":"java中有几种类型的流？","text":"1. Java中有几种类型的流？ JDK为每种类型的流提供了一些抽象类类以供继承，请说出它们分别是那些类？ IO流用来处理设备之间的数据传输 流的分类： 流按处理数据类型分为两种：字节流与字符流 流按数据流向分:输入流、输出流 字符流的抽象基类： Reader用于读取字符流的抽象类 Writer写入字符流的抽象类 字节流的抽象基类： InputStream此抽象类是表示字节输入流的所有类的超类。 OutputStream此抽象类是表示输出字节流的所有类的超类 结构图：","link":"/2017/03/08/2017-03-08-java%E4%B8%AD%E6%9C%89%E5%87%A0%E7%A7%8D%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%B5%81%EF%BC%9F/"},{"title":"面试经验1","text":"经验分享 面临大学的毕业，我和大多数毕业生一样，对这个世界是那么的迷茫和无知，如今找工作也快一个月了，依然任何的进展，北京这个地方固然美好，但是人才济济，Android市场的异常冷门让我雪上加霜，貌似我现在连一个实习生的资格都过不了，我是该好好反思自己的水平，不能再停留在原来那个阶段，下面我总结几个我考过的题型，也是为了分享一下记录自己的不足好去应对未来的挑战。 实现一个单例模式代码 这道题虽然简单，但是埋下了一个坑，你是否考虑过在多线程的情况下，你得单例会不会产生多个对象呢？ 还有效率问题呢？ 下面是一个简单的单例，咱们看看会产生什么问题123456789101112class A { //存放引用的变量 private static A ins = null; //私有化构造方法 private A() {} public static A getInstance(){ if (ins == null){ ins = new A(); } return ins; }｝ 实验效果： 哇，居然在高并发的情况下创建了两个！所以这种单例不严谨，会在高并发的情况下产生问题，我们来改进一下加入同步的内容。 2.修改上面的代码加入同步的内容 123456789101112class A { //存放引用的变量 private static A ins = null; //私有化构造方法 private A() {} public synchronized static A getInstance(){ if (ins == null){ ins = new A(); } return ins; }｝ 实验效果图： 哇塞，达到了同步的效果，但是这里还需要注意一个问题就是，当我们在进行大量的并发的时候锁住了这个类以后是不是全部都需要进入锁判断了？ 这样效率不就大大降低了么？所以这里我们还需要改进一下， 做到不多做一点的无用功。 3.修改上面的代码加入多层次判断快速创建对象，不多做一点无用功！ 123456789101112131415161718class A { //存放引用的变量 private static A ins = null; //私有化构造方法 private A() {} ```java //加入同步 public static A getInstance() { if (ins == null) { synchronized (A.class){ if (ins == null){ ins = new A(); } } } return ins; }｝ 这里就不展示效果图了，改进的是运行的速度，这里在首次创建对象的时候会进入锁判断，当创建完成以后，其他的都会直接返回对象，不再进入锁等待着中，大大的提高了运行的效率","link":"/2017/03/28/2017-03-28-%E9%9D%A2%E8%AF%95%E7%BB%8F%E9%AA%8C1/"},{"title":"实现SOAP接口得适配","text":"博主工作一周了，上一周里遇到了一个难题，就是对方提供的是SOAP协议制作出来的接口，让我们进行适配，其实这个技术已经淘汰了，不过对方是erp也不可能因为你而改写什么对吧，这里我们就分析一下怎么解决这个问题。 SOAP（Simple Object Access Protocol） 简单对象访问协议 SOAP是基于XML的建议协议，可使用应用程序的HTTP之上进行信息交换或简单地说：SOAP使用用于访问网络服务的协议。 什么是SOAP？ SOAP 指__简易对象访问协议__ SOAP 是一种__通信协议__ SOAP 用于__应用程序之间__的通信 SOAP 是一种__发送消息__的格式 SOAP 被设计用来__通过因特网__进行通信 SOAP 独立于平台 SOAP 独立于语言 SOAP 基于XML SOAP 很简单并可扩展 SOAP 允许你__绕过防火墙__ SOAP 将被作为__W3C标准__来发展 6.约定的交互格式交互格式 123456789&lt;soapenv:Envelope xmlns:soapenv=&quot;http://schemas.xmlsoap.org/soap/envelope/&quot; xmlns:sen=&quot;http://pi.want-want.com/ZRFCARW_1/Sender_Syn&quot;&gt; &lt;soapenv:Header/&gt; &lt;soapenv:Body&gt; &lt;sen:MT_ZRFCARW01_Req&gt; &lt;!--Optional:--&gt; &lt;IM_OBJID&gt;{json数据}&lt;/IM_OBJID&gt; &lt;/sen:MT_ZRFCARW01_Req&gt; &lt;/soapenv:Body&gt;&lt;/soapenv:Envelope&gt; 12345678910&lt;soapenv:Envelope xmlns:soapenv=&quot;http://schemas.xmlsoap.org/soap/envelope/&quot; xmlns:sen=&quot;http://pi.want-want.com/ZRFCARW_2/Sender_Syn&quot;&gt; &lt;soapenv:Header/&gt; &lt;soapenv:Body&gt; &lt;sen:MT_ZRFCARW02_Req&gt; &lt;!--Optional:--&gt; &lt;IM_JSON&gt;{json数据}&lt;/IM_JSON&gt; &lt;/sen:MT_ZRFCARW02_Req&gt; &lt;/soapenv:Body&gt;&lt;/soapenv:Envelope&gt; 鉴权方式– BaseAuthor验证方式 解决办法 通过对方提供wsdl文档文件，使用soapUI软件进行测试解析 soapUI工具图： 当我们使用这个工具跑通接口后，这个时候还没有完成我们还必须要使用一个工具就是postman这个接口测试工具，有人可能要问了，为啥用soapui这个工具呢？答案是：交互数据接口，我们需要读取wsdl文件啊，才能知道交互的数据结构呢。 使用postman软件进行接口的再次测试。 从soapUI中获取相关信息进行解析使用postman进行测试 填入交互数据 返回的结果图 我们获取到了正式的数据，我们还需要提取xml中的json数据，我得解决方案是通过正则匹配的形式提取json，还有另一种办法，因为数据的格式还是比较简单的，也可以采取替换的原则，去掉json的前后无用的xml标签数据 一下是我写的通信代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778function ApiNetManager($json = null, $isID = true){ //根地址 $baseUrl = 'url'; $port = 'port'; $username = 'username'; $password = 'password'; //统一消息返回格式 $info = array( 'code' =&gt; 0, 'message' =&gt; '', 'data' =&gt; null ); //验证json的正确性 if (is_null(json_decode($json))) { return false; } //构建网络请求 $curl = curl_init(); if ($isID) {//验证课程ID curl_setopt_array($curl, array( CURLOPT_PORT =&gt; $port, CURLOPT_URL =&gt; $baseUrl . ':' . $port . &quot;/XISOAPAdapter/MessageServlet?senderParty=&amp;senderService=BC_OEXAM&amp;receiverParty=&amp;receiverService=&amp;interface=SI_ZRFCARW01_Out_Syn&amp;interfaceNamespace=http%3A%2F%2Fpi.want-want.com%2FZRFCARW_1%2FSender_Syn&quot;, CURLOPT_RETURNTRANSFER =&gt; true, CURLOPT_ENCODING =&gt; &quot;utf8&quot;, CURLOPT_MAXREDIRS =&gt; 10, CURLOPT_TIMEOUT =&gt; 30, CURLOPT_HTTP_VERSION =&gt; CURL_HTTP_VERSION_1_1, CURLOPT_CUSTOMREQUEST =&gt; &quot;POST&quot;, CURLOPT_POSTFIELDS =&gt; &quot;&lt;soapenv:Envelope xmlns:soapenv=\\&quot;http://schemas.xmlsoap.org/soap/envelope/\\&quot; xmlns:sen=\\&quot;http://pi.want-want.com/ZRFCARW_1/Sender_Syn\\&quot;&gt;&lt;soapenv:Header/&gt;&lt;soapenv:Body&gt;&lt;sen:MT_ZRFCARW01_Req&gt;&lt;IM_OBJID&gt;{$json}&lt;/IM_OBJID&gt;&lt;/sen:MT_ZRFCARW01_Req&gt;&lt;/soapenv:Body&gt;&lt;/soapenv:Envelope&gt;&quot;, CURLOPT_HTTPHEADER =&gt; array( &quot;authorization: Basic &quot; . base64_encode($username . ':' . $password), &quot;cache-control: no-cache&quot;, &quot;content-type: application/xml&quot;, ), )); } else {//回传考试成绩接口 curl_setopt_array($curl, array( CURLOPT_PORT =&gt; &quot;50000&quot;, CURLOPT_URL =&gt; $baseUrl . ':' . $port . &quot;/XISOAPAdapter/MessageServlet?senderParty=&amp;senderService=BC_OEXAM&amp;receiverParty=&amp;receiverService=&amp;interface=SI_ZRFCARW02_Out_Syn&amp;interfaceNamespace=http%3A%2F%2Fpi.want-want.com%2FZRFCARW_2%2FSender_Syn&quot;, CURLOPT_RETURNTRANSFER =&gt; true, CURLOPT_ENCODING =&gt; &quot;&quot;, CURLOPT_MAXREDIRS =&gt; 10, CURLOPT_TIMEOUT =&gt; 30, CURLOPT_HTTP_VERSION =&gt; CURL_HTTP_VERSION_1_1, CURLOPT_CUSTOMREQUEST =&gt; &quot;POST&quot;, CURLOPT_POSTFIELDS =&gt; &quot;&lt;soapenv:Envelope xmlns:soapenv=\\&quot;http://schemas.xmlsoap.org/soap/envelope/\\&quot; xmlns:sen=\\&quot;http://pi.want-want.com/ZRFCARW_2/Sender_Syn\\&quot;&gt;&lt;soapenv:Header/&gt;&lt;soapenv:Body&gt;&lt;sen:MT_ZRFCARW02_Req&gt;&lt;IM_JSON&gt;{$json}&lt;/IM_JSON&gt;&lt;/sen:MT_ZRFCARW02_Req&gt;&lt;/soapenv:Body&gt;&lt;/soapenv:Envelope&gt;&quot;, CURLOPT_HTTPHEADER =&gt; array( &quot;authorization: Basic &quot; . base64_encode($username . ':' . $password), &quot;cache-control: no-cache&quot;, &quot;content-type: application/xml&quot;, ), )); } //执行网络请求 $response = curl_exec($curl); $err = curl_error($curl); if ($err) { $info['code'] = 500; $info['message'] = '服务器异常，请稍后再试'; } else if (strstr($response, '&lt;title&gt;Error Report&lt;/title&gt;')) {//请求成功权限没有通过 $info['code'] = 302; $info['message'] = '服务器请求权限未通过请联系管理员!'; } else {//请求并权限通过 if ($isID) {//验证课程id的json查找 preg_match(&quot;/{.+}/&quot;, $response, $match);//查找json } else {//考试成绩回传的json查找 preg_match('/\\[{.*?\\}]/is', $response, $match); } $jsonArr = json_decode($match[0], true);//解析json $info['code'] = 200; $info['message'] = '请求成功，成功返回数据'; $info['data'] = $jsonArr; } return $info['code'] == 0 ? false : $info;} 至此我们完成了数据的代码的填写，相关具体测试我就不多说了，这里我加入了标准的接口返回形式，一边后续的代码可以更加精确地判断问题出在哪里，好了就到这里，谢谢大家的观看。","link":"/2017/04/17/2017-04-17-%E5%AE%9E%E7%8E%B0SOAP%E6%8E%A5%E5%8F%A3%E5%BE%97%E9%80%82%E9%85%8D/"},{"title":"学习Larvel(Day 1)","text":"今天开始博主要开始学习Larvel啦并将他用在实际的项目中去一、 目录结构 12345678910111213141516171819202122232425# / 根目录 |--- app 应用目录(包含应用程序的核心代码) |--- Console 包含应用所有自定义的 Artisan 命令 |--- Events 用来放置 事件类 的 |--- Exceptions 应用的异常处理 |--- Http 包含你的控制器、中间件和请求 |--- Jobs 用于存放 队列任务(在你执行 make:job 命令生成任务类时，才会出现) |--- Listeners |--- Mail 邮件发送类(默认不存在，但是可以通过执行 make:mail 命令生成，Mail 目录包含邮件发送类，邮件对象允许你在一个地方封装构建邮件所需的所有业务逻辑，然后使用 Mail::send 方法发送邮件。) |--- Notifications 包含应用发送的所有通知，比如事件发生通知（目录默认不存在，你可以通过执行 make:notification 命令创建， ） |--- Policies 包含了所有的授权策略类（通过执行 ·make:policy· 命令来创建） |--- Providers 包含应用的 服务提供者 （Providers 目录包含应用的 服务提供者 。服务提供者在启动应用过程中绑定服务到容器、注册事件，以及执行其他任务，为即将到来的请求处理做准备。） |--- bootstrap 引导目录(目录包含了几个框架启动和自动加载设置的文件) |--- cache (包含框架为提升性能所生成的文件，如路由和服务缓存文件) |--- config 配置文件 |--- database 数据库(包含了数据迁移及填充文件) |--- public 包含了 Laravel 的 HTTP 入口文件 index.php 和前端资源文件（图片、JavaScript、CSS等） |--- resources 资源目录（包含了视图、原始的资源文件 (LESS、SASS、CoffeeScript) ，以及语言包。） |--- routes 路由目录（包含了应用的所有路由定义） |--- storage 包含编译后的 Blade 模板、基于文件的 session、文件缓存和其它框架生成的文件 |--- app 用于存储应用程序使用的任何文件 |--- framework 目录被用于保存框架生成的文件及缓存 |--- logs 目录包含了应用程序的日志文件 |--- tests 包含自动化测试 |--- vendor 包含所有 Composer 依赖 请求的整体流程 larvel的请求入口是public/index.PHP,我们在开始部署的时候不管你用的是apache还是nginx都会指向这个文件，这是程序的入口。 public/index.php 文件 12345678910111213141516171819202122232425262728293031/*|--------------------------------------------------------------------------| 注册自定义加载类|--------------------------------------------------------------------------*/require __DIR__.'/../bootstrap/autoload.php';/*|--------------------------------------------------------------------------| 引入Larvel应用实例（composer生成的自定义加载器定义）|--------------------------------------------------------------------------*/$app = require_once __DIR__.'/../bootstrap/app.php';/*|--------------------------------------------------------------------------| 创建一个自身应用实例（[服务容器](https://docs.golaravel.com/docs/5.4/container/)）|--------------------------------------------------------------------------*/$kernel = $app-&gt;make(Illuminate\\Contracts\\Http\\Kernel::class);$response = $kernel-&gt;handle( $request = Illuminate\\Http\\Request::capture());$response-&gt;send();$kernel-&gt;terminate($request, $response); 以上是初步分析，后续会继续跟进，大家可以多提提意见，让我成长更快~","link":"/2017/05/10/2017-05-10-%E5%AD%A6%E4%B9%A0Larvel-Day-1/"},{"title":"给定路径统计当前以及子目录文件个数","text":"可能是紧张的关系，当时大脑一片空白，没有想到解题思路，今天一起过来学习一下 遇到一个问题前咱们必须先仔细的想想思路 首先判断当前给定的路径是否是文件 文件则统计，目录则取出子目录进行递归 一轮统计结束后即可输出结果 12345678910111213141516171819/** * 统计路径包括子目录的文件数量 * Created by teddy on 2017/3/29. */public class FileUtils { public static int count=0; public static int getCount(String path){ File file = new File(path); if (file.isDirectory()){ File[] files = file.listFiles(); for (int i = 0; i &lt; files.length; i++) { getCount(files[i].getPath()); } }else{ count++; } return count; }} 测试运行： 准备目录和文件 运行结果： 之前一直没有去联系过相关的题目，造成了我笔试的失力，所以基础不扎实，这点一定要堵住，也希望大家也多加练习，在未来能写出一手漂亮的程序！","link":"/2017/03/30/2017-03-30-%E7%BB%99%E5%AE%9A%E8%B7%AF%E5%BE%84%E7%BB%9F%E8%AE%A1%E5%BD%93%E5%89%8D%E4%BB%A5%E5%8F%8A%E5%AD%90%E7%9B%AE%E5%BD%95%E6%96%87%E4%BB%B6%E4%B8%AA%E6%95%B0/"},{"title":"Larvel学习 （Day 02）","text":"Larvel 服务容器学习 一个好的系统并不在代码多么复杂，框架多么多么大，在我的理解中框架跑得快不一定成功，不跌跟头才叫赢。 我们需要弄懂这么几个概念：依赖注入，服务容器 依赖注入: 这是一个花哨的名词，其实质上是通过【构造方法】或者【setter】来对本类中需要用到的以来进行注入。 下面是官方的样例： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?php namespace App\\Http\\Controllers; use App\\User; use App\\Repositories\\UserRepository; use App\\Http\\Controllers\\Controller; class UserController extends Controller { /** * User Repository 的实现。 * * @var UserRepository */ protected $users; /** * 创建新的控制器实例。 * * @param UserRepository $users * @return void */ public function __construct(UserRepository $users) { $this-&gt;users = $users; } /** * 显示指定用户的详细信息。 * * @param int $id * @return Response */ public function show($id) { $user = $this-&gt;users-&gt;find($id); return view('user.profile', ['user' =&gt; $user]); } } 讲解：在这个例子中，控制器 UserController 需要从数据源中获取 users 。因此，我们要 注入 可以获取 users 的服务。在这种情况下， UserRepository 可能是通过使用 Eloquent 来从数据库中获取 user 信息。因为 UserRepository 是通过注入获取，所以我们可以容易地切换为其他实现。当测试应用程序时，我们还可以轻松地 「mock」 ，或创建假的 UserRepository 实例。 服务容器: 管理类的以来和运行依赖注入的有效管理工具, Laravel服务容器主要承担两个作用：绑定与解析，服务容器的结构如下： 绑定 所谓的绑定就是将接口与实现建立对应关系。几乎所有的服务容器绑定都是在服务提供者中完成，也就是在服务提供者中绑定。 如果一个类没有基于任何接口那么就没有必要将其绑定到容器。容器并不需要被告知如何构建对象，因为它会使用 PHP 的反射服务自动解析出具体的对象。 也就是说，如果需要依赖注入的外部资源如果没有接口，那么就不需要绑定，直接利用服务容器进行解析就可以了，服务容器会根据类名利用反射对其进行自动构造。 bind绑定 绑定有多种方法，首先最常用的是bind函数的绑定 绑定自身 1$this-&gt;app-&gt;bind('App\\Services\\RedisEventPusher', null); 绑定闭包 1234567$this-&gt;app-&gt;bind('HelpSpot\\API', function ($app) { return new HelpSpot\\API();});//闭包直接提供实现方式$this-&gt;app-&gt;bind('HelpSpot\\API', function ($app) { return new HelpSpot\\API($app-&gt;make('HttpClient'));});//需要依赖注入 绑定接口 1234$this-&gt;app-&gt;bind( 'App\\Contracts\\EventPusher', 'App\\Services\\RedisEventPusher'); singleton绑定 singleton 方法绑定一个只需要解析一次的类或接口到容器，然后接下来对容器的调用将会返回同一个实例： 123$this-&gt;app-&gt;singleton('HelpSpot\\API', function ($app) { return new HelpSpot\\API($app-&gt;make('HttpClient'));}); instance绑定 我们还可以使用 instance 方法绑定一个已存在的对象实例到容器，随后调用容器将总是返回给定的实例： 12$api = new HelpSpot\\API(new HttpClient);$this-&gt;app-&gt;instance('HelpSpot\\Api', $api); Context绑定 有时侯我们可能有两个类使用同一个接口，但我们希望在每个类中注入不同实现，例如，两个控制器依赖 Illuminate\\Contracts\\Filesystem\\Filesystem 契约的不同实现。Laravel 为此定义了简单、平滑的接口： 12345678910111213141516171819202122use Illuminate\\Support\\Facades\\Storage;use App\\Http\\Controllers\\VideoController;use App\\Http\\Controllers\\PhotoControllers;use Illuminate\\Contracts\\Filesystem\\Filesystem;$this-&gt;app-&gt;when(StorageController::class) -&gt;needs(Filesystem::class) -&gt;give(function () { Storage::class });//提供类名$this-&gt;app-&gt;when(PhotoController::class) -&gt;needs(Filesystem::class) -&gt;give(function () { return new Storage(); });//提供实现方式$this-&gt;app-&gt;when(VideoController::class) -&gt;needs(Filesystem::class) -&gt;give(function () { return new Storage($app-&gt;make(Disk::class)); });//需要依赖注入 原始值绑定 我们可能有一个接收注入类的类，同时需要注入一个原生的数值比如整型，可以结合上下文轻松注入这个类需要的任何值： 123$this-&gt;app-&gt;when('App\\Http\\Controllers\\UserController') -&gt;needs('$variableName') -&gt;give($value); 数组绑定 123app()['service'] = function(){ return new Service();}; 标签绑定 少数情况下，我们需要解析特定分类下的所有绑定，例如，你正在构建一个接收多个不同 Report 接口实现的报告聚合器，在注册完 Report 实现之后，可以通过 tag 方法给它们分配一个标签： 123456789 $this-&gt;app-&gt;bind('SpeedReport', function () { // });$this-&gt;app-&gt;bind('MemoryReport', function () { //});$this-&gt;app-&gt;tag(['SpeedReport', 'MemoryReport'], 'reports'); 这些服务被打上标签后，可以通过 tagged 方法来轻松解析它们： 123$this-&gt;app-&gt;bind('ReportAggregator', function ($app) { return new ReportAggregator($app-&gt;tagged('reports'));}); extend扩展 extend是在当原来的类被注册或者实例化出来后，可以对其进行扩展： 12345678910111213141516171819202122232425262728public function testExtendInstancesArePreserved(){ $container = new Container; $container-&gt;bind('foo', function () { $obj = new StdClass; $obj-&gt;foo = 'bar'; return $obj; }); $obj = new StdClass; $obj-&gt;foo = 'foo'; $container-&gt;instance('foo', $obj); $container-&gt;extend('foo', function ($obj, $container) { $obj-&gt;bar = 'baz'; return $obj; }); $container-&gt;extend('foo', function ($obj, $container) { $obj-&gt;baz = 'foo'; return $obj; }); $this-&gt;assertEquals('foo', $container-&gt;make('foo')-&gt;foo); $this-&gt;assertEquals('baz', $container-&gt;make('foo')-&gt;bar); $this-&gt;assertEquals('foo', $container-&gt;make('foo')-&gt;baz);} Rebounds与Rebinding 绑定是针对接口的，是为接口提供实现方式的方法。我们可以对接口在不同的时间段里提供不同的实现方法，一般来说，对同一个接口提供新的实现方法后，不会对已经实例化的对象产生任何影响。但是在一些场景下，在提供新的接口实现后，我们希望对已经实例化的对象重新做一些改变，这个就是 rebinding 函数的用途。下面就是一个例子： 123456789101112131415161718192021222324252627282930313233343536abstract class Car{ public function __construct(Fuel $fuel) { $this-&gt;fuel = $fuel; } public function refuel($litres) { return $litres * $this-&gt;fuel-&gt;getPrice(); } public function setFuel(Fuel $fuel) { $this-&gt;fuel = $fuel; }}class JeepWrangler extends Car{//}interface Fuel{ public function getPrice();}class Petrol implements Fuel{ public function getPrice() { return 130.7; }} 我们在服务容器中是这样对car接口和fuel接口绑定的： 123456789$this-&gt;app-&gt;bind('fuel', function ($app) { return new Petrol;});$this-&gt;app-&gt;bind('car', function ($app) { return new JeepWrangler($app['fuel']);});$this-&gt;app-&gt;make('car'); 如果car被服务容器解析实例化成对象之后，有人修改了 fuel 接口的实现，从 Petrol 改为 PremiumPetrol： 123$this-&gt;app-&gt;bind('fuel', function ($app) { return new PremiumPetrol;}); 由于 car 已经被实例化，那么这个接口实现的改变并不会影响到 car 的实现，假若我们想要 car 的成员变量 fuel 随着 fuel 接口的变化而变化，我们就需要一个回调函数，每当对 fuel 接口实现进行改变的时候，都要对 car 的 fuel 变量进行更新，这就是 rebinding 的用途： 12345$this-&gt;app-&gt;bindShared('car', function ($app) { return new JeepWrangler($app-&gt;rebinding('fuel', function ($app, $fuel) { $app['car']-&gt;setFuel($fuel); }));}); 今天先到这里，未来会继续学习和总结。","link":"/2017/05/17/2017-05-17-Larvel%E5%AD%A6%E4%B9%A0-%EF%BC%88Day-02%EF%BC%89/"},{"title":"php文档注释规范总结和学习","text":"PHP标准注释列表 @api @author @category @copyright @deprecated @example @filesource @global @ignore @internal @license @link @method @package @param @property-read @property-write @return @see @since @source @subpackage @throws @todo @uses @var @version @api 语法要求 官方示例如下：1234567891011/** * This method will not change until a major release. * * @api * * @return void */ function showVersion() { &lt;...&gt; } @author 语法要求 @author [name] [] 官方示例如下： 1234/** * @author My Name * @author My Name &lt;my.name@example.com&gt; */ @category 语法要求 @category [description] 官方示例 123456/** * Page-Level DocBlock * * @category MyCategory * @package MyPackage */ @copyright 语法要求 @copyright [description] 描述 此注释专用于对软件版权进行注释 官方示例123/*** @copyright 1997-2005 The PHP Group*/ @deprecated 语法要求 @deprecated [version] [description] 官方示例 12345678910/*** @deprecated* @deprecated 1.0.0* @deprecated No longer used by internal code and not recommended.* @deprecated 1.0.0 No longer used by internal code and not recommended.*/function count(){ &lt;...&gt;} @example 语法要求 @example [location] [start-line] [number-of-lines] ] [description] 官方示例 123456789/** * @example example1.php Counting in action. * @example http://example.com/example2.phps Counting in action by a 3rd party. * @example &quot;My Own Example.php&quot; My counting. */ function count() { &lt;...&gt; } @filesource @filesource标签用于告诉phpDocumentor将当前文件的源包含在解析结果中。 语法要求 @filesource 说明@filesource标签告诉phpDocumentor将当前文件包含在解析输出中。由于这仅适用于整个文件的源代码，所以必须在文件级PHPDoc中使用此标记。任何其他位置都将被忽略。 当包含此标签时，phpDocumentor将压缩文件内容并使用Base64进行编码，以便可以由变压器处理。任何能够显示源代码的模板都可以在抽象语法树中读取相关文件元素中的源子元素。 官方示例 123/ ** * @filesource * / @global @global标签用于通知phpDocumentor全局变量_or_其用法。(非必须) 语法要求 @global [ Type ] [name] @global [ Type ] [description] @ignore @ignore标签用于告诉phpDocumentor结构元素不被phpDocumentor处理。 语法要求 @ignore [] 官方示例 1234567891011if（$ ostest）{ / ** *这个定义将是“Unix”或“Windows” * / define（“OS”，“Unix”）;} else { / ** * @ignore * / define（“OS”，“Windows”）;} @api 语法要求 官方示例 @api 语法要求 官方示例 @api 语法要求 官方示例 @api 语法要求 官方示例 @api 语法要求 官方示例 @api 语法要求 官方示例 @api@api@api","link":"/2017/05/19/2017-05-19-php%E6%96%87%E6%A1%A3%E6%B3%A8%E9%87%8A%E8%A7%84%E8%8C%83%E6%80%BB%E7%BB%93%E5%92%8C%E5%AD%A6%E4%B9%A0/"},{"title":"好久没写博客了","text":"转眼间我已经毕业了踏上了人生新的征程，大学这四年我每逢假期都会去做兼职，我做过的很多呢，卖冰激凌，烤鱿鱼，烤鱼片，爆米花冰激凌，快餐店的鲜榨果汁和汉堡等我都有触及，之前在大学觉得一点意思也没有，总是想出去工作，先自我毕业了也签工作，感受颇多，我想对我在公司的感受做一个总结吧。 初入职场 当我来到新公司一切幻想都是那么的美好，曾一度幻想着自己子公司发挥多大作用，出任CEO、赢取白富美、走上人生巅峰~ 入场三个月 目前公司产品是考试培训系统，按照当今来说竞争真的非常激励了，公司使用的是之前来员工写的框架oFrame ，怎么说呢框架在八年前非常的厉害，给我的感觉和TP3时代的产物，公司老大安排我解决新题型的问题，目前把 考试系统面临新题型问题，我经过三天研究真的放弃了，真的代码太难维护了，毕竟那个年的产物没有命名空间什么的，而且更没有composer这样的先进版本管理的产物。 目前我维护接口这块内容，因为接口和旧框架有很大的问题，比如数据都是SQL直接查询，大量的代码充斥着面临各种安全危机，xss，CSRF，SQL注入等常见漏洞比比皆是，系统内部饱含各种bug和问题。 目前我的想法是先从我这里开刀动用现今的Laravel(PHP先进框架) 因为公司业务目前业务都是针对于客户主机获取内容，这次应对的目标是在未来ios的APP能够尽快完成出来让用户先用起来，没有办法我只能继续沿用致前任写的接口，尽快的赶工出来。 在未来我做如下规划： Laravel负责基础框架快速完成平台化的工作 docker 负责环境这块的配置达到运维一条命令即可完成部署 radis 作为内存机数据库完成token这里快速查询修改 mysql 作为主要数据来源，负责数据的持久化，这里我准备使用主从分离技术来完成 centos 服务器这里统一采用centos免费的服务器系统 以上是我的想法和规划，目前需要尽快出来的的版本这里为了能够尽快完成必须完成session集群化共享的内容，达到快速完成现有版本的实现。 总结我会在接下来的日子继续学习，学习各种最新的架构，争取这一年能够自己独立完成php框架的学习和编写，在未来成为架构师的道路上继续努力。","link":"/2017/07/26/2017-07-26-%E5%A5%BD%E4%B9%85%E6%B2%A1%E5%86%99%E5%8D%9A%E5%AE%A2%E4%BA%86/"},{"title":"使用mysql-router工具实现数据库读写分离，数据库负载均衡","text":"研究公司oFrame框架发现，我们框架内大量的sql扫表语句严重的影响了数据查询速度和产品使用的各种问题，为此我准备先从第一步入手去增数据的性能，让我们一起学一下吧. 一、 环境准备 mysql-router 简单的负载均衡组件 mysql5.6 mysql centos7 Vmware ** mysql-router 简介 ** MySQL的路由器是轻量级的中间件，提供您的应用程序和任何后端MySQL服务器之间的透明路由。它可用于各种各样的使用情况，如通过有效的路由数据库流量到合适的后端MySQL服务器提供高可用性和可扩展性。可插拔的体系结构还使开发者来扩展MySQL的路由器自定义的用例。 故障转移 典型地，高度可用的MySQL设置由一个单一的主站和多个从机，并且它是由应用程序来处理故障切换，在情况下，MySQL主变得不可用。使用MySQL路由器，应用程序连接将被透明基于负载平衡策略路由，不实现自定义应用程序代码。 负载均衡 MySQL的路由器通过在服务器池分配数据库的连接提供了额外的可扩展性和性能。举例来说，如果你有一个复制的一套MySQL服务器的，MySQL的路由器可以在一个循环的方式分发应用程序连接到他们。 可插入式架构 MySQL的路由器的可插入式架构使MySQL的开发人员能够轻松地与附加功能延伸产品，以及提供MySQL用户能够创建提供了无限的可能性自己的自定义插件的能力。MySQL的路由器目前包括一些核心插件，其中包括： 连接路由插件，它确实基于连接的路由，这意味着它转发MySQL的数据包发送到后端服务器，而不检查或修改它们，从而提供最大的吞吐量。的元数据高速缓存插件，它提供了透明的客户端负载平衡，路由和故障转移到组复制和InnoDB群集。 二、环境搭建 这里centos搭建和Vmware不再阐述，mysql的安装也不在讲解，重点讲解配置步骤和实现mysql-router功能 安装mysql-router 进入官网下载页面：点我去往下载页面 这里我选择Red Hat Enterprise Linux 7 / Oracle Linux 7也就是上图中的第一个rpm包进行下载 为了在虚拟机中能够方便的复制，我这里下载过程中复制下载地址到虚拟机中使用**[ wget ]**命令进行下载 12345678910111213141516[root@localhost ~]# wget https://cdn.mysql.com//Downloads/MySQL-Router/mysql-router-2.1.4-1.el7.x86_64.rpm--2017-07-28 14:57:02-- https://cdn.mysql.com//Downloads/MySQL-Router/mysql-router-2.1.4-1.el7.x86_64.rpmResolving cdn.mysql.com (cdn.mysql.com)... 2.17.63.195Connecting to cdn.mysql.com (cdn.mysql.com)|2.17.63.195|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 1947576 (1.9M) [application/x-redhat-package-manager]Saving to: ‘mysql-router-2.1.4-1.el7.x86_64.rpm’100%[============================================================&gt;] 1,947,576 773KB/s in 2.5s 2017-07-28 14:57:10 (773 KB/s) - ‘mysql-router-2.1.4-1.el7.x86_64.rpm’ saved [1947576/1947576][root@localhost ~]# rpm -i mysql-router-2.1.4-1.el7.x86_64.rpm 经过上面的步骤mysql-router已经安装完毕，这里mysql安装不在叙述 三、负载均衡架构规划 我由于使用的是虚拟机我这里设定以下几个服务器 1.Mysql Middleware 安装着mysql-router专门用于mysql入口负责机器的主从分配等问题 2.Mysql Master 数据库主库，用于数据的读写 3.Mysql Salve 数据库从库 我对结构做了如下划分和IP分配，详情见图: 四、配置服务1.Mysql Middleware (router主机) 默认rpm安装位置在/usr/bin/mysqlrouter 为了个人意愿我把日志logs和配置文件mysqlrouter.ini都存放在/usr/local/mysql-router下 下面开始新建配置文件，设置port:8000为读写端口 port:8001为只读端口 12345678910111213141516171819202122232425262728[root@localhost mysql-router]# mkdir logs[root@localhost mysql-router]# vi mysqlrouter.ini[DEFAULT] logging_folder=usr/local/mysql-router/logs [logger] level=INFO [routing:basic_failover] bind_address=192.168.1.186 bind_port=000 destinations=192.168.1.189:3306 mode=read-write max_connections=1024 max_connect_errors=100 client_connect_timeout=9 [routing:balancing]# 绑定router的IP即可 bind_address=192.168.1.186 #绑定端口 bind_port=8001 #数据库地址，会轮训访问 destinations = 192.168.1.193:3306#指定模式为只读mode=read-only #设置最大连接数 max_connections=65535max_connect_errors=100client_connect_timeout = 9 [keepalive] interval = 60 以上是配置文件内容，注释了一部分 启动mysqlrouter(设置自己的配置文件即可，我已经在配置文件目录了就按照下方启动即可) 1[root@localhost mysql-router]# mysqlrouter -c ./mysqlrouter.ini &amp; 验证mysqlrouter是否启动（下图情况为启动成功） 123[root@localhost mysql-router]# netstat -tunlp|grep mysqlrouter tcp 0 0 0.0.0.0:8000 0.0.0.0:* LISTEN 71271/mysqlrouter tcp 0 0 0.0.0.0:8001 0.0.0.0:* LISTEN 71271/mysqlrouter 经过以上步骤已经完成router配置了，如果主库从库都可以的话即可使用客户端通过8000端口访问测试，如果不能访问通过下面这组命令查看错误日志 1[root@localhost mysql-router]# tail logs/mysqlrouter.log 2.Mysql Master 数据库主库 配置从库复制账号 1234MySQL [(none)]&gt; grant replication scale on *.* to '账号名'@'主机域' identifed by '账号密码'；MySQL [(none)]&gt; flush privileges; 配置主库的主从复制文件my.ini主要增加或修改一下选项 12345678#服务器ID唯一标识，错了，无法复制server-id = 1#指定复制库binlog-do-db=text#以下数据库不复制binlog-ignore-db=mysql 经过修改以后从其mysql主库的任务就完成了，接下来配置从库 Mysql Salve 数据库从库(设定主库信息进行读写配置) 登入数据库后查看服务器ID不可以和主库相同，切记！ 1234567MySQL [(none)]&gt; show variables like 'server_id';+---------------+-------+| Variable_name | Value |+---------------+-------+| server_id | 2 |+---------------+-------+1 row in set (0.02 sec) 查询主库配置信息 12345678MySQL [(none)]&gt; show master status \\G File: mysql-bin.000006 Position: 2647 Binlog_Do_DB: text Binlog_Ignore_DB: mysqlExecuted_Gtid_Set:1 row in set (0.00 sec) 获取File和Position即可 写入主库信息 1234567891011MySQL [(none)]&gt; change master to -&gt;master_host='192.168.1.189',//主库地址 -&gt;master_port=3306, //主库端口 -&gt;master_user='master', //主库同步账户名 -&gt;master_password='master', //同步账号密码 -&gt;master_log_file='mysql-bin.000005',//对应主库File -&gt;master_log_pos=3195;//对应主库Position Query OK, 0 rows affected, 2 warnings (0.02 sec)MySQL [(none)]&gt; start slave; //启动同步Query OK, 0 rows affected (0.00 sec) 为了保证数据同步，请一定要空表操作，避免报错 如果同步请使用MySQL [(none)]&gt; show slave status \\G 查看具体错误 其它从库全部遵循这个配置原则即可完成，多少个从库都可以 五、 总结通过本次学习我对数据库负载均衡有了很大的了解，我以后也会继续学习更深入的集群化知识，为以后架构师的梦想做知识筹备，也希望我出的这个经验分享能给大家一个很好的参考，也是目前能提高公司产品服务器这块速度慢，在并发情况下发生数据库罢工的解决方案，目前这个演示仅仅是一个主库和从库，大家回去练习可以多建立从库进行大并发访问测试，今天的分享就到这里，祝大家工作顺利。","link":"/2017/07/28/2017-07-28-%E4%BD%BF%E7%94%A8mysql-router%E5%B7%A5%E5%85%B7%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"title":"23种设计模式英文中文对照","text":"序号 模式名 英文名 1 简单工厂模式 Simple Factory Pattern 2 工厂方法模式 Factory Method Pattern 3 抽象工厂模式 Abstract Factory Pattern 4 建造者模式 Builder Pattern 5 原型模式 Prototype Pattern 6 单例模式 Singleton Pattern 7 适配器模式 Adapter Pattern 8 桥梁模式(桥接模式) Bridge Pattern 9 组合模式 Composite Pattern 10 装饰模式 Decorator Pattern 11 门面模式(外观模式) Facade Pattern 12 享元模式 Flyweight Pattern 13 代理模式 Proxy pattern 14 责任链模式 Chain of Responsibility Pattern 15 命令模式 Command Pattern 16 解释器模式 Interpreter Pattern 17 迭代器模式 Iterator Pattern 18 中介者模式 Mediator Pattern 19 备忘录模式 Memento Pattern 20 观察者模式 Observer Pattern 21 状态模式 State Pattern 22 策略模式 Strategy Pattern 23 模板方法模式 Template Method Pattern 24 访问者模式 Visitor Pattern 接下来的一段日子里我将陆续更新每个设计模式的做法，多学习设计模式防止被祭天~ 哈哈哈","link":"/2017/09/11/2017-09-11-23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%8B%B1%E6%96%87%E4%B8%AD%E6%96%87%E5%AF%B9%E7%85%A7/"},{"title":"单例模式(PHP实现)","text":"介绍一下单例的应用场景:最简单的场景就是数据库了， 还有框架中基础的应用配置加载了，使用单例模式有如下好处，避免过多的new对象造成大量资源廊坊和超出最大连接数而产生应用down机问题，可以全局设立一个单访问点避免多出访问点造成难以维护的现象，便于调试直接可以设立日志记录全局设立统一节点，避免导出var_dump，print_r的现象 一、类图单例相对结构上比较简单，总体实现想法就是全局设立一个访问点，全局共同使用一个对象，不会创建多余的对象。 二、实现思路完成单例需要满足以下需求：1、全局隐藏私有构造方法，预防通过new来创建对象。2、隐藏私有克隆方法，预防通过克隆创建对象3、对外暴露一个静态的Instance方法提供统一对外的获取对象的方式 三、实现单例模式1234567891011121314151617181920212223242526class Singleton{ //存放实例 private static $_instance = null; //私有化构造方法、 private function __construct() { throw new Exception(&quot;禁止构造&quot;); } //私有化克隆方法 private function __clone() { } //公有化获取实例方法 public static function getInstance() { if (!(self::$_instance instanceof Singleton)) { self::$_instance = new Singleton(); } return self::$_instance; }} 通过Singleon::getInstance();来使用单例 2、使用trait方式实现123456789101112131415161718192021222324252627282930//PHP trait 使用 Trait Singleton{ //存储实例 private static $_instance = null; //私有化克隆方法 private function __clone(){} //提供统一对外的实例方法 public static function getInstance(){ $class = __CLASS__; if (!(self::$_instance instanceof $class)){ self::$_instance = new $class(); } return self::$_instance; } } class DB{ use Singleton; private function __construct() { echo '实例被创建了'; } } DB::getInstance(); 好了今天的单例就到这里，以后会陆续上其它的设计模式，并且会通过PHP和JAVA两种语言或者多种来去实现来加深印象，好的设计模式能让系统更加的简介代码复用更高，大家努力学习吧","link":"/2017/09/23/2017-09-23-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F-PHP%E5%AE%9E%E7%8E%B0/"},{"title":"Spring boot 修改启动banner内容","text":"我们在启动Spring boot时候会出现以下情况 我们可以将它改成自己产品的内容修改方式如下 在 src/main/resources/banner.txt 创建并加入内容: 12345678910 _ (_) ___ _ __ ___ _____ _ __ / _ \\| '__| \\ \\ / / _ \\| '_ \\| (_) | | | |\\ V / (_) | | | |\\___/|_| |_| \\_/ \\___/|_| |_|${spring-boot.version}${spring-boot.formatted-version} 在banner.txt 文件末尾可以加入${spring-boot.version}${spring-boot.formatted-version}用来显示最新的版本等信息 再次启动项目会看到如下结果 每日名言：不要向这个世界认输，因为你还有牛逼的梦想！","link":"/2017/12/19/2017-12-19-Spring-boot-%E4%BF%AE%E6%94%B9%E5%90%AF%E5%8A%A8banner%E5%86%85%E5%AE%B9/"},{"title":"Snowflake（twitter 64位唯一ID生成算法）","text":"在很多业务场景中会遇到id唯一的问题，我就遇到很多，数据库中的自增的生成，接下来我们一起学习唯一ID生成算法 Snowflake 组成结构 雪花算法总共64位组成(不要问我为什么，这是具体规定啊) 1.1 正负码1位 （通常为0） 1.2 毫秒级时间41位 1.3 节点码10位 由于设计之初是分布式ID，所以这里基本上是5位节点码+机器码5位 1.4 序列码12位 累加计数器 最大1毫秒产生4095个不重复的id 代码实现","link":"/2017/12/09/2017-12-09-Snowflake%EF%BC%88twitter-64%E4%BD%8D%E5%94%AF%E4%B8%80ID%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95%EF%BC%89/"},{"title":"spring boot配置多环境","text":"我是经常会遇到不同环境配置不同参数的情况，例如我们在本地开发环境的端口1111 但是测试环境就要换成2222，线上环境端口就要换成8080端口，为了应对这种情况， spring boot给我们提供了更成熟的方案。 配置公共文件 spring boot默认配置文件是application.properties这里我们采用另外一种简便格式 application.yml 我们配置公共内容如下: 12345678orivon: version: 1.2.0 apiversion: 1.2.1spring: profiles: active: dev 第一个是配置我们产品的相关版本信息，这样升级的时候可以很容易看到版本等信息更好的维护产品的运行，第二行就是指明我们默认加载开发环境下的配置内容 创建环境的配置文件 我们假设如下几个环境场景:测试环境，开发环境，线上环境，我们分配配置如下几个文件（spring boot环境配置文件遵循以下格式appilication-{$varsion}.yml）否组不予加载 测试环境: application-test.yml 开发环境: application-dev.yml 线上环境: application-prod.yml 分别制定在里面写个server.port={$port} 我这里设置测试1111，开发8888，线上8080 大家可以随便设置，来测试端口是否已经发生了改变3. 加载不同的配置文件 讲完了环境配置文件，我们要切换配置文件怎么办呢？当我们编写完了程序，需要进行打包，这里我就打包成jar文件了，通过mvn install来打包jar文件，生成完毕后会存放在target/XXXX.1.0.0-XXX.jar的文件,我们只需要拷贝到线上环境通过java -jar XXXX.jar --spring.profiles.active=prod后面这个就是配置使用哪个配置文件啦，使用test就可以啦，不用带其他的内容，即可完成配置，并成功运行啦，给个成功运行的效果图 每日名言：生命力的意义在于拼搏，因为世界本身就是一个竞技场。","link":"/2017/12/20/2017-12-20-spring-boot%E9%85%8D%E7%BD%AE%E5%A4%9A%E7%8E%AF%E5%A2%83/"},{"title":"php共享内存学习","text":"php中进程间通信介绍的很少，今天我来学习学习怎么实现共享内存的实现 安装 安装地址 需要在安装的时候添加 –enable-shmop 来启用该函数的功能 可以通过 ** phpinfo(); ** 来确认是否安装成功，我这里查看 ** shmop support =&gt; enabled ** 代表启用成功了 主要函数 123456shmop_close — 关闭共享内存块shmop_delete — 删除共享内存块shmop_open — 创建或打开共享内存块shmop_read — 从共享内存块中读取数据shmop_size — 获取共享内存块的大小shmop_write — 向共享内存块中写入数据 与此相关的还有一个很重要的函数：ftok，通过文件的 inode 信息（nix 上通过 stat 或 ls -i 命令查看）创建 IPC 的唯一 key（文件/文件夹的 inode 是唯一的）。这个函数在 Linux 上也是直接调用同名的系统函数实现，Windows 上还是使用一些封装。 有个需要稍微注意的点：shmop_open 的第二个参数是个 flag，类似 fopen 的第二个参数，其取值有以前几个： 123456“a” 只读访问“c” 如果内存片段不存在，则创建，如果存在，则可读写；“w” 读写；“n” 创建新的内存片段，如果同样 key 的已存在，则会创建失败，这是为了安全使用共享内存考虑。 程序 1234567891011//新建一块共享内存（并取得唯一nodeID）$shm_key = ftok(__FILE__,'t');//打开改共享内存文件，采用片段不存在则创建策略$shm_id = shmop_open($shm_key,'c',0644,8);# 读取读取共享内存（8字节读取）$count = (int) shmop_read($shm_id, 0, 8) + 1;shmop_write($shm_id, str_pad($count, 8, '0', STR_PAD_LEFT), 0);echo $count;shmop_close($shm_id); 运行效果图 即使进程关闭重新开启依然能够正常读取数据！ 一定要把握长度，否则可能出现读取异常的问题","link":"/2018/02/05/2018-02-05-php%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E5%AD%A6%E4%B9%A0/"},{"title":"php信号量控制","text":"上一篇文章学习到了php的共享内存，但是仅仅这个是不够的，我们还需要更精确的控制，避免多个进程同时写入共享内存的情况发生，我们还需奥信号量的控制等内容 准备PHP 也提供了类似的内置扩展 sysvsem（这个扩展在 Windows 环境下没有，文档中将 ftok 函数也归到这个扩展中，但实际上 ftok 是在标准函数库中提供的，所以在 Windows 下也是可用的）。 检查扩展是否支持通过phpinfo() 检测加载情况 1234sysvmsgsysvmsg support =&gt; enabledRevision =&gt; $Id: 8fc76436c42ce984b2ad34ae6b27082d5e66c104 $ 有以上这样的就属于已经正常加载可以使用这些功能啦 知识点介绍 sem_get() 获取信号标识 sem_acquire() 获取信号量 sem_release() 信号量发布 sem_remove() 删除信号量 shm_attach() 创建或打开共享内存段 shm_detach() 断开与共享内存段的连接 相关函数列表 样例 1234567891011121314$id_key = ftok(__FILE__, 't');$sem_id = sem_get($id_key);# 请求信号控制权if (sem_acquire($sem_id)) { $shm_id = shmop_open($id_key, 'c', 0644, 8); # 读取并写入数据 $count = (int) shmop_read($shm_id, 0, 8) + 1; shmop_write($shm_id, str_pad($count, 8, '0', STR_PAD_LEFT), 0); // echo shmop_read($shm_id, 0, 8); # 关闭内存块 shmop_close($shm_id); # 释放信号 sem_release($sem_id);} 测试 最后一定要注意关闭信号量，以免造成上一个信号量一直被占用造成下一个无法使用的问题！！","link":"/2018/02/05/2018-02-05-php%E4%BF%A1%E5%8F%B7%E9%87%8F%E6%8E%A7%E5%88%B6/"},{"title":"爬虫常见请求头总结","text":"1.引言在我们编写爬虫应用的时候经常会遇到不同浏览器返回不同内容的情况，所以这里收集常见的\bUserAgent来供以后查阅。 2.PC端的UserAgent safari 5.1 – MAC User-Agent:Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50 safari 5.1 – Windows User-Agent:Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50 Firefox 38esr User-Agent:Mozilla/5.0 (Windows NT 10.0; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0 IE 11 User-Agent:Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; .NET4.0C; .NET4.0E; .NET CLR 2.0.50727; .NET CLR 3.0.30729; .NET CLR 3.5.30729; InfoPath.3; rv:11.0) like Gecko IE 9.0 User-Agent:Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0; IE 8.0 User-Agent:Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0) IE 7.0 User-Agent:Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0) IE 6.0 User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1) Firefox 4.0.1 – MAC User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1 Firefox 4.0.1 – Windows User-Agent:Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1 Opera 11.11 – MAC User-Agent:Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11 Opera 11.11 – Windows User-Agent:Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11 Chrome 17.0 – MAC User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_0) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11 傲游（Maxthon） User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Maxthon 2.0) 腾讯TT User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; TencentTraveler 4.0) 世界之窗（The World） 2.x User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1) 世界之窗（The World） 3.x User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; The World) 搜狗浏览器 1.x User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SE 2.X MetaSr 1.0; SE 2.X MetaSr 1.0; .NET CLR 2.0.50727; SE 2.X MetaSr 1.0) 360浏览器 User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE) Avant User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Avant Browser) Green Browser User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1) 3.移动端UserAgent safari iOS 4.33 – iPhone User-Agent:Mozilla/5.0 (iPhone; U; CPU iPhone OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5 safari iOS 4.33 – iPod Touch User-Agent:Mozilla/5.0 (iPod; U; CPU iPhone OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5 safari iOS 4.33 – iPad User-Agent:Mozilla/5.0 (iPad; U; CPU OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5 Android N1 User-Agent: Mozilla/5.0 (Linux; U; Android 2.3.7; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1 Android QQ浏览器 For android User-Agent: MQQBrowser/26 Mozilla/5.0 (Linux; U; Android 2.3.7; zh-cn; MB200 Build/GRJ22; CyanogenMod-7) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1 Android Opera Mobile User-Agent: Opera/9.80 (Android 2.3.4; Linux; Opera Mobi/build-1107180945; U; en-GB) Presto/2.8.149 Version/11.10 Android Pad Moto Xoom User-Agent: Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13 BlackBerry User-Agent: Mozilla/5.0 (BlackBerry; U; BlackBerry 9800; en) AppleWebKit/534.1+ (KHTML, like Gecko) Version/6.0.0.337 Mobile Safari/534.1+ WebOS HP Touchpad User-Agent: Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.0; U; en-US) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/233.70 Safari/534.6 TouchPad/1.0 Nokia N97 User-Agent: Mozilla/5.0 (SymbianOS/9.4; Series60/5.0 NokiaN97-1/20.0.019; Profile/MIDP-2.1 Configuration/CLDC-1.1) AppleWebKit/525 (KHTML, like Gecko) BrowserNG/7.1.18124 Windows Phone Mango User-Agent: Mozilla/5.0 (compatible; MSIE 9.0; Windows Phone OS 7.5; Trident/5.0; IEMobile/9.0; HTC; Titan) UC无 User-Agent: UCWEB7.0.2.37/28/999 UC标准 User-Agent: NOKIA5700/ UCWEB7.0.2.37/28/999 UCOpenwave User-Agent: Openwave/ UCWEB7.0.2.37/28/999 UC Opera User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; ) Opera/UCWEB7.0.2.37/28/999 每日一言：勤学的人，总是感到时间过得太快；懒惰的人，却总是埋怨时间跑得太慢。","link":"/2018/02/19/2018-02-19-%E7%88%AC%E8%99%AB%E5%B8%B8%E8%A7%81%E8%AF%B7%E6%B1%82%E5%A4%B4%E6%80%BB%E7%BB%93/"},{"title":"系统性能指标","text":"这篇文章记录查看系统负载相关方法 1. uptime命令uptime命令能够打印系统总共运行了多长时间和系统的平均负载。uptime命令可以显示的信息显示依次为：现在时间、系统已经运行了多长时间、目前有多少登陆用户、系统在过去的1分钟、5分钟和15分钟内的平均负载。 12uptime 10:43:21 up 27 days, 1:46, 1 user, load average: 0.04, 0.06, 0.06 现在时间，开机27天，，1个用户，负载1、5、15分钟的平均负载 2. top命令top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。 123456789101112131415161718192021222324252627top - 10:56:33 up 27 days, 1:59, 1 user, load average: 0.00, 0.01, 0.05Tasks: 120 total, 1 running, 119 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.2 us, 0.2 sy, 0.0 ni, 99.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 3881720 total, 937900 free, 646416 used, 2297404 buff/cacheKiB Swap: 0 total, 0 free, 0 used. 2913336 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND12837 yuekang 20 0 157704 2172 1516 R 0.7 0.1 0:00.11 top 1729 root 20 0 848356 20452 3000 S 0.3 0.5 35:57.94 YDService 2432 root 20 0 534628 10416 2080 S 0.3 0.3 108:29.12 barad_agent 1 root 20 0 43344 3748 2500 S 0.0 0.1 2:19.44 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.37 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0:03.52 ksoftirqd/0 5 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H 7 root rt 0 0 0 0 S 0.0 0.0 0:01.28 migration/0 8 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcu_bh 9 root 20 0 0 0 0 S 0.0 0.0 12:47.92 rcu_sched 10 root rt 0 0 0 0 S 0.0 0.0 0:10.91 watchdog/0 11 root rt 0 0 0 0 S 0.0 0.0 0:09.58 watchdog/1 12 root rt 0 0 0 0 S 0.0 0.0 0:01.46 migration/1 13 root 20 0 0 0 0 S 0.0 0.0 0:03.42 ksoftirqd/1 15 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/1:0H 17 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kdevtmpfs 18 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 netns 19 root 20 0 0 0 0 S 0.0 0.0 0:00.77 khungtaskd 20 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 writeback 21 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kintegrity 显示的内容非常全，平均负载等内容都被显示出来了 3. w命令12345~w 10:57:38 up 27 days, 2:00, 1 user, load average: 0.00, 0.01, 0.05USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATyk pts/0 120.57.161.139 10:43 2.00s 0.04s 0.00s w w命令的主要功能其实是显示目前登入系统的用户信息。但是与who不同的是，w命令功能更加强大，w命令还可以显示：当前时间，系统启动到现在的时间，登录用户的数目，系统在最近1分钟、5分钟和15分钟的平均负载。然后是每个用户的各项数据，项目显示顺序如下：登录帐号、终端名称、远 程主机名、登录时间、空闲时间、JCPU、PCPU、当前正在运行进程的命令行。 机器正常负载范围对于机器的Load到底多少算正常的问题，一直都是很有争议的，不同人有着不同的理解。对于单个CPU，有人认为如果Load超过0.7就算是超出正常范围了。也有人认为只要不超过1都没问题。也有人认为，单个CPU的负载在2以下都可以接受。为什么会有这么多不同的理解呢，是因为不同的机器除了CPU影响之外还有其他因素的影响，运行的程序、机器内存、甚至是机房温度等都有可能有区别。比如，有些机器用于定时执行大量的跑批任务，这个时间段内，Load可能会飙的比较高。而其他时间可能会比较低。那么这段飙高时间我们要不要去排查问题呢？我的建议是，最好根据自己机器的实际情况，建立一个指标的基线（如近一个月的平均值），只要日常的load在基线上下范围内不太大都可以接收，如果差距太多可能就要人为介入检查了。但是，总要有个建议的阈值吧，关于这个值。阮一峰在自己的博客中有过以下建议： 当系统负荷持续大于0.7，你必须开始调查了，问题出在哪里，防止情况恶化。 当系统负荷持续大于1.0，你必须动手寻找解决办法，把这个值降下来。 当系统负荷达到5.0，就表明你的系统有很严重的问题，长时间没有响应，或者接近死机了。你不应该让系统达到这个值。 上指标都是基于单CPU的，但是现在很多电脑都是多核的。所以，对一般的系统来说，是根据cpu数量去判断系统是否已经过载（Over Load）的。如果我们认为0.7算是单核机器负载的安全线的话，那么四核机器的负载最好保持在3(4*0.7 = 2.8)以下。还有一点需要提一下，在Load Avg的指标中，有三个值，1分钟系统负荷、5分钟系统负荷，15分钟系统负荷。我们在排查问题的时候也是可以参考这三个值的。一般情况下，1分钟系统负荷表示最近的暂时现象。15分钟系统负荷表示是持续现象，并非暂时问题。如果load15较高，而load1较低，可以认为情况有所好转。反之，情况可能在恶化。 如何降低负载导致负载高的原因可能很复杂，有可能是硬件问题也可能是软件问题。如果是硬件问题，那么说明机器性能确实就不行了，那么解决起来很简单，直接换机器就可以了。前面我们提过，CPU使用、内存使用、IO消耗都可能导致负载高。如果是软件问题，有可能由于Java中的某些线程被长时间占用、大量内存持续占用等导致。建议从以下几个方面排查代码问题：1、是否有内存泄露导致频繁GC 2、是否有死锁发生 3、是否有大字段的读写 4、会不会是数据库操作导致的，排查SQL语句问题。这里还有个建议，如果发现线上机器Load飙高，可以考虑先把堆栈内存dump下来后，进行重启，暂时解决问题，然后再考虑回滚和排查问题。 本文摘自：https://juejin.im/post/5b0262edf265da0b9b079fa7?utm_source=gold_browser_extension","link":"/2018/05/22/2018-05-22-%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/"},{"title":"PHP内存管理器机制","text":"概述内存是每个工程师逃避不了的问题，了解内存管理机制更有助于了解PHP7内存分配的原理，更好的使用PHP7这门语言 PHP7内存管理器： PHP脚本运行不是直接从系统中申请的，而是调用了Zend Memory Manager (Zend 内存管理器)提供的一系列接口函数\b来间接申请内存，如果管理器内存够用，直接分配PHP程序，如果不够用，\b则自动向系统中申请。 \bPHP7核心代码在zend_alloc.c中实现，一共有三种规格的内存 序号 规格 尺寸 1 Huge(chunk) 申请内存大于2M，直接调用系统分配，分配若干个chunk 2 Large(page) 申请内存大于3K(3/4 page_size)，小于2044K(511 page_size)，分配若干个page 3 Small(slot) 申请内存小于等于3K(3/4 page_size) zval的示意图 Huge分配也是最大力度的分配这个分配是直接向系统中申请的，但一次会申请多个，有合适了则立即返回内存区域， Large分配一个chunk对应512个page，但是第一个page会始终被chunk结构占用着，可用的也就511个page大小。如果申请多个page的话分配的时候这些page都是连续的 。如果直到最后一个chunk也没找到则重新分配一个新的chunk并插入chunk链表,chunk-&gt;free_map利用bitmap来记录每组的page的使用情况 slot分配small内存总共有30种固定大小的规格：8,16,24,32,40,48,56,64,80,96,112,128 … 1792,2048,2560,3072 Byte，这称之为slot，这些slot的大小是有规律的:最小的slot大小为8byte，前8个slot依次递增8byte，后面每隔4个递增值乘以2 php7 内存对齐PHP7会对是内存进行对齐例如申请300B内存大小的内存，经过内存管理器的申请，加入是256B对齐，当申请300B内存则会拿到512B的内存，申请对其内存应该是对其内存数的整数倍,其中不符合的会将这个不对齐的区域进行释放掉","link":"/2018/06/12/2018-06-12-PHP%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%99%A8%E6%9C%BA%E5%88%B6/"},{"title":"PHP7之线程安全","text":"以前总觉得php是多进程单线程的，每个访问都是一个单独的进程互相不干扰\b各自的数据，数据是隔离的，最早的PHP都是来一个用户新建一个进程，访问结束就销毁这个进程，但是这样非常的浪费性能，后续PHP-fpm的出现将这个进程复用实现了，大大的优化速度，用户来了以后是分配一个线程的空闲进程来服务，用户离开就回到空闲里面给后面的用户使用。现在php早已实现了多线程的功能，今天我来学学这个多线程是怎么实现的。 目前PHP多数是单线程环境，比如cli、fpm、cgi，每个进程只启动一个主线程，这种情况下也就不存在线程安全的情况了，在多线程环境下就需要考虑线程安全的问题了，PHP中有很多的全局变量这个如果多线程公用的情况下就会造成线程安全你的问题，PHP专门做了一个安全机制：Zend线程安全(Zend Thread Safe, ZTS) PHP为了解决这个问题做了一个程安全资源管理器(Thread Safe Resource Mananger, TSRM)，其主要实现的原理就是单个进程有一个公用的全局\b变量，如果多线程互相\b贡献不安全，就把这些数据拷贝若干份，保证每个线程都有自己的全局变量，这样线程之间互不干扰完美的解决这个安全的问题. PHP中定义如下： 1234567891011121314typedef struct { size_t size; //资源的大小 ts_allocate_ctor ctor; //初始化函数 ts_allocate_dtor dtor; int done;} tsrm_resource_type;struct _tsrm_tls_entry { void **storage; //资源数组 int count; //拥有的资源数:storage数组大小 THREAD_T thread_id; //所属线程id tsrm_tls_entry *next;}; 一个资源如果想被多线程使用，就必须想TSRM\b注册资源，TSRM会给这个资源分配一个ID,并把资源相关数据初始化保存到tsrm_resource_type中去，\b所有的线程必须通过这个ID来访问这个资源，如果线程第一次访问这个资源，TSRM会初始化这个资源，也就是复制一份出来给这个线程使用包括后续访问。 tsrm_tls_table 保存着所有线程物理位置，这个位置通过根据线程id与预设置的线程数tsrm_tls_table_size取模得到的 每个线程拥有一个tsrm_tls_entry结构，当前线程的所有资源保存在storage数组中，它是一个链表结构，查找资源时首先根据:线程id % tsrm_tls_table_size得到一个tsrm_tls_entry，然后开始遍历链表比较thread_id确定是否是当前线程的。线程本地存储(Thread Local Storage, TLS)，在创建完当前线程的tsrm_tls_entry后会把这个值保存到当前线程的TLS中，这样在ts_resource()获取资源时中就可以通过tsrm_tls_get()直接取到了，节省加锁检索的时间。","link":"/2018/06/13/2018-06-13-PHP7%E4%B9%8B%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"},{"title":"PHP7-垃圾回收机制","text":"垃圾回收是一种自动的内存管理机制，当一个变量在程序中不再被使用时，应该予以释放，这种内存资源管理称为垃圾回收。其中一种垃圾回收方式是使用引用计数，通过对数据存储的物理空间多附加一个计数器空间，当其他数据与其相关是，计数器加一，反之，相关解除时计数器减一。定期检查各存储对象的计数器，计数器为零的话，则认为该对象已经被抛弃而应将其所占物理空间回收。 下面是GC的核心数据结构: 123456789101112struct _zend_refcounted { uint32_t refcount; union { struct { ZEND_ENDIAN_LOHI_3( zend_uchar type, zend_uchar flags, uint16_t gc_info) } v; uint32_t type_info; } u;}; zend_refcounted由32位bit的refcount和32bit的type_info组成 \b1. type 第一个字节记录当前元素的类型 flags 第二个字节用来记录数据类型 gc_info 后面的两个字节标记当前元素的颜色和垃圾回收池中的位置，其中高地址的两位用来标记颜色。 3.1 颜色有 黑色，白色，灰色，紫色 php性能提升 gc垃圾收集器下面是gc_globals的结构 gc_root_buffer 是一个双向链表，同时记录引用计数的相关信息，zend_gc_globals维护者gc的整个信息，这里列出个字段的含义。 序号 字段 含义 1 gc_enabled 是否开启gc 2 gc_active 垃圾回收算法是否运行 3 gc_full 垃圾缓冲区是否满了，在debug模式下有用 4 buf 垃圾缓冲区，PHP7默认大小为10 000个节点位置，0位置保留 5 roots 指向缓冲区中最新加入的可能是垃圾的元素 6 unused 指向缓冲区中没有使用的位置，在没有启动垃圾回收算法前，指向空 7 first_unused 指向缓冲区中第一个未使用的位置，新的元素插入缓冲区后，指针会后移动一位 8 last_unused 指向缓冲区中最后一个位置 9 to_free 待释放的列表 10 next_to_free 下一个待释放的列表 11 gc_runs 记录gc算法的运行的次数，当缓冲区满了，才会运行gc算法 12 collected 记录gc算法回收的垃圾数 垃圾收集过程 要求数据类型是数组和对象 没有在缓冲区中存在过 没有被标记过 将其gc_info标记为紫色的，且记录其在缓冲区的位置 当缓冲区满时，再收集新的元素会出发垃圾回收算法。 垃圾流转图： 回收过程分为4部分 对roots环中每一个元素进行深度优先遍历，将每个元素中gc_info为紫色的标记元素为灰色，且引用计数-1 扫描roots换中gc_info为灰色的元素，如果发现引用计数仍旧大于0，说明这个元素在其他地方使用，那么将其颜色重新标记为黑色，如果发现其引用计数是0则将其标记为白色，该过程同样为深度优先遍历。 扫描roots换，将gc_info颜色为黑色的的元素从roots移除，然后对roots中颜色为白色的元素进行深度有限遍历，将其引用计数+1，然后将roots链表移动到待释放列表中（to_free）中等待回收","link":"/2018/06/14/2018-06-14-PHP7-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/"},{"title":"array常用函数整理","text":"array_chunk array_chunk — 将一个数组分割成多个 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253$arr = ['a', 'b', 'c', 'd', 'e', 'f'];var_dump(array_chunk($arr, 2));var_dump(array_chunk($arr, 2, false));结果：array(3) { [0]=&gt; array(2) { [0]=&gt; string(1) &quot;a&quot; [1]=&gt; string(1) &quot;b&quot; } [1]=&gt; array(2) { [0]=&gt; string(1) &quot;c&quot; [1]=&gt; string(1) &quot;d&quot; } [2]=&gt; array(2) { [0]=&gt; string(1) &quot;e&quot; [1]=&gt; string(1) &quot;f&quot; }}array(3) { [0]=&gt; array(2) { [0]=&gt; string(1) &quot;a&quot; [1]=&gt; string(1) &quot;b&quot; } [1]=&gt; array(2) { [0]=&gt; string(1) &quot;c&quot; [1]=&gt; string(1) &quot;d&quot; } [2]=&gt; array(2) { [0]=&gt; string(1) &quot;e&quot; [1]=&gt; string(1) &quot;f&quot; }} array_column array_column — 返回数组中指定的一列 123456789101112131415161718192021222324252627282930313233343536373839404142434445$arr = [ [ 'id' =&gt; 123, 'name' =&gt; 'name1' ], [ 'id' =&gt; 124, 'name' =&gt; 'name2' ], [ 'id' =&gt; 125, 'name' =&gt; 'name3' ], [ 'id' =&gt; 126, 'name' =&gt; 'name4' ],];var_dump(array_column($arr, 'name'));var_dump(array_column($arr, 'name', 'id'));结果:array(4) { [0]=&gt; string(5) &quot;name1&quot; [1]=&gt; string(5) &quot;name2&quot; [2]=&gt; string(5) &quot;name3&quot; [3]=&gt; string(5) &quot;name4&quot;}array(4) { [123]=&gt; string(5) &quot;name1&quot; [124]=&gt; string(5) &quot;name2&quot; [125]=&gt; string(5) &quot;name3&quot; [126]=&gt; string(5) &quot;name4&quot;} array_combine array_combine — 创建一个数组，用一个数组的值作为其键名，另一个数组的值作为其值 1234567891011121314$key = ['one', 'two', 'three'];$value = [1,2,3];var_dump(array_combine($key,$value));array(3) { [&quot;one&quot;]=&gt; int(1) [&quot;two&quot;]=&gt; int(2) [&quot;three&quot;]=&gt; int(3)} array_count_values123456789101112$array = array(1, &quot;hello&quot;, 1, &quot;world&quot;, &quot;hello&quot;);var_dump(array_count_values($array));array(3) { [1]=&gt; int(2) [&quot;hello&quot;]=&gt; int(2) [&quot;world&quot;]=&gt; int(1)} array_diff array_diff — 计算数组的差集 1234567891011$array1 = array(&quot;a&quot; =&gt; &quot;green&quot;, &quot;red&quot;, &quot;blue&quot;, &quot;red&quot;);$array2 = array(&quot;b&quot; =&gt; &quot;green&quot;, &quot;yellow&quot;, &quot;red&quot;);$result = array_diff($array1, $array2);var_dump($result);array(1) { [1]=&gt; string(4) &quot;blue&quot;} array_fill array_fill — 用给定的值填充数组 1234567891011121314151617181920212223$a = array_fill(5, 6, 'banana');$b = array_fill(-2, 4, 'pear');print_r($a);print_r($b);Array( [5] =&gt; banana [6] =&gt; banana [7] =&gt; banana [8] =&gt; banana [9] =&gt; banana [10] =&gt; banana)Array( [-2] =&gt; pear [0] =&gt; pear [1] =&gt; pear [2] =&gt; pear) array_filter array_filter — 用回调函数过滤数组中的单元 12345678910111213141516171819202122$arr = [1,2,3,4,6,7,8,9,10];$res = array_filter($arr, function ($val) { return $val % 2 == 0;});var_dump($res);array(5) { [1]=&gt; int(2) [3]=&gt; int(4) [4]=&gt; int(6) [6]=&gt; int(8) [8]=&gt; int(10)} array_flip array_flip — 交换数组中的键和值 12345678910111213$input = array(&quot;oranges&quot;, &quot;apples&quot;, &quot;pears&quot;);$flipped = array_flip($input);var_dump($flipped);array(3) { [&quot;oranges&quot;]=&gt; int(0) [&quot;apples&quot;]=&gt; int(1) [&quot;pears&quot;]=&gt; int(2)} array_keys array_keys — 返回数组中部分的或所有的键名 123456789101112$input = array(&quot;oranges&quot;, &quot;apples&quot;, &quot;pears&quot;);$flipped = array_keys($input);var_dump($flipped);array(3) { [0]=&gt; int(0) [1]=&gt; int(1) [2]=&gt; int(2)} array_map array_map — 为数组的每个元素应用回调函数 123456789101112131415$input = array(&quot;oranges&quot;, &quot;apples&quot;, &quot;pears&quot;);$res = array_map(function ($val){ return $val . '123';}, $input);var_dump($res);array(3) { [0]=&gt; string(10) &quot;oranges123&quot; [1]=&gt; string(9) &quot;apples123&quot; [2]=&gt; string(8) &quot;pears123&quot;} array_rand array_rand — 从数组中随机取出一个或多个单元 1234567891011121314$input = array(&quot;oranges&quot;, &quot;apples&quot;, &quot;pears&quot;);$res = array_rand($input, 2);var_dump($res);var_dump($input[$res[1]]);array(2) { [0]=&gt; int(1) [1]=&gt; int(2)}string(5) &quot;pears&quot; array_replace array_replace — 使用传递的数组替换第一个数组的元素 1234567891011121314151617$base = array(&quot;orange&quot;, &quot;banana&quot;, &quot;apple&quot;, &quot;raspberry&quot;);$replacements = array(0 =&gt; &quot;pineapple&quot;, 4 =&gt; &quot;cherry&quot;);$replacements2 = array(0 =&gt; &quot;grape&quot;);$basket = array_replace($base, $replacements, $replacements2);print_r($basket);Array( [0] =&gt; grape [1] =&gt; banana [2] =&gt; apple [3] =&gt; raspberry [4] =&gt; cherry) array_slice array_slice — 从数组中取出一段 123456789$base = array(&quot;orange&quot;, &quot;banana&quot;, &quot;apple&quot;, &quot;raspberry&quot;);var_dump(array_slice($base, 0, 2));array(2) { [0]=&gt; string(6) &quot;orange&quot; [1]=&gt; string(6) &quot;banana&quot;} arsort arsort — 对数组进行逆向排序并保持索引关系 123456789101112131415$fruits = array(&quot;d&quot; =&gt; &quot;aemon&quot;, &quot;a&quot; =&gt; &quot;brange&quot;, &quot;b&quot; =&gt; &quot;canana&quot;, &quot;c&quot; =&gt; &quot;dpple&quot;);arsort($fruits);var_dump($fruits);array(4) { [&quot;c&quot;]=&gt; string(5) &quot;dpple&quot; [&quot;b&quot;]=&gt; string(6) &quot;canana&quot; [&quot;a&quot;]=&gt; string(6) &quot;brange&quot; [&quot;d&quot;]=&gt; string(5) &quot;aemon&quot;} asort asort — 对数组进行排序并保持索引关系 123456789101112131415$fruits = array(&quot;d&quot; =&gt; &quot;aemon&quot;, &quot;a&quot; =&gt; &quot;brange&quot;, &quot;b&quot; =&gt; &quot;canana&quot;, &quot;c&quot; =&gt; &quot;dpple&quot;);asort($fruits);var_dump($fruits);array(4) { [&quot;d&quot;]=&gt; string(5) &quot;aemon&quot; [&quot;a&quot;]=&gt; string(6) &quot;brange&quot; [&quot;b&quot;]=&gt; string(6) &quot;canana&quot; [&quot;c&quot;]=&gt; string(5) &quot;dpple&quot;} sort sort — 对数组排序 1234567891011121314151617$fruits = array(&quot;lemon&quot;, &quot;orange&quot;, &quot;banana&quot;, &quot;apple&quot;);sort($fruits);var_dump($fruits);array(4) { [0]=&gt; string(5) &quot;apple&quot; [1]=&gt; string(6) &quot;banana&quot; [2]=&gt; string(5) &quot;lemon&quot; [3]=&gt; string(6) &quot;orange&quot;} list list — 把数组中的值赋给一组变量 1234567891011$fruits = array(&quot;lemon&quot;, &quot;orange&quot;, &quot;banana&quot;, &quot;apple&quot;);list($a, $b, $c) = $fruits;echo $a,$b,$c, &quot;\\n&quot;;list($a,,$c) = $fruits;echo $a,$c, &quot;\\n&quot;;lemonorangebananalemonbanana","link":"/2018/06/19/2018-06-19-array%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E6%95%B4%E7%90%86/"},{"title":"PHP7- I/O模型学习","text":"四种响应模型 同步：调用后，死等，等到结果为止 异步：调用立即返回，等到有结果通知 阻塞：数据没有处理完成前不返回 非阻塞：调用立即返回等到有结果通知我 五种I/O模型 阻塞I/O (Blocking I/O) 当进程进行系统调用时，内核开始了IO的第一个阶段准备数据，准备完成交给内核缓冲最后拷贝到用户进程的内存中，然后才解锁进程，这个等待过程称为阻塞。 非阻塞I/O (Non-Blocking I/O) 进程在第二阶段被阻塞，\b调用的时候没有阻塞，\b第二阶段开始不断轮训CPU询问数据是否准备完毕，所以比较消耗CPU资源的模型 I/O复用（I/O Multiplexing) IO执行的两个阶段进程都是阻塞的，在这次完整的过程中，进程发起了两次系统调用。和阻塞IO不同的\b是第一阶段可以等待多个\b调用结果 信号驱动的I/O (Signal Driven I/O) 只有在IO执行的第二阶段阻塞了进程，该模型在IO执行的第一阶段，当数据完成之后，会主动通知进程数据已经准备好，对进程做一个回调，通知分为两种，一位水平触发，及时进程不响应会一直发送通知，二为边缘触发，即只通知一次 异步I/O (Asynchrnous I/O) 当进程发起系统调用后，立刻就可以开始做其它事情，然后知道IO执行的两个阶段都完成之后，内核会给集成发送通知，告之进程已经完成处理了。","link":"/2018/06/21/2018-06-21-PHP7-IO%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/"},{"title":"yar学习","text":"Yar(yet another RPC framework), RPC框架, 和现有的RPC框架(xml-rpc, soap)不同, 这是一个轻量级的框架, 支持多种打包协议(msgpack, json, php), 并且最重要的一个特点是, 它是可并行化的… 特征 快速，简单，简单 并发RPC调用 支持多个数据包装器（内置php，json，msgpack） 支持多种传输协议（http实现，稍后将支持tcp / unix） 详细的调试信息 环境准备作者要求至少满足以下条件 PHP 5.2+ Curl Json Msgpack (Optional)： 新型二进制打包协议比json和xml快很多，和序列化的效率差不多 环境安装 安装yar 1pecl install yar 安装msgpack 1pecl install msgpack 运行时配置 1234567yar.timeout //默认5000（ms）yar.connect_timeout //默认值1000（ms）yar.packager //默认“php”，当使用--enable-msgpack然后默认“msgpack”构建时，它应该是“php”，“json”，“msgpack”yar.debug //默认关闭yar.expose_info //默认为On，是否输出GET请求的API信息yar.content_type //默认的“application / octet-stream”yar.allow_persistent //默认关闭 编写第一个server123456789101112131415161718class Api { /** * 测试Name * @param $key * @param $value * @return mixed */ public function getName($key, $value= 'foo'){ return $value; } public function getB($key) { }}$service = new Yar_Server(new Api());$service-&gt;handle(); 直接访问网页可以看到对应的内容已经展现出来了 编写第一个客户端请求rpc接口1234$client = new Yar_Client(&quot;https://admin.myhost.top/Api/&quot;);$result = $client-&gt;getName(&quot;key&quot;,&quot;my value&quot;);var_dump($result); 请求后可以获得如下结果 1string(8) &quot;my value&quot; 至此一个简单的rpc功能完成了，后续会学习更深层的使用方式","link":"/2018/06/24/2018-06-24-yar%E5%AD%A6%E4%B9%A0/"},{"title":"Yii-mail模块学习","text":"邮件已经是办公必备了，在Yii中已经封装了一套完整邮件代码，帮助我们快速的建立系统邮件的邮件发送功能，其易于扩展的设计结构功能开发变得简化。 邮件发送格式 一个正常的邮件具有：发件人、收件人、回复地址、抄送地址、主题、正文 Yii中mail模块是怎么设计的？ 分三块，分别是管理邮件发送相关的，邮件格式相关的，邮件事件相关 1.1 MessageInterface 定义了邮件相关\b格式相关 1.2 MailerInterface定义邮件应该具有相关功能 1.3 BaseMessage实现了个\b邮件send和toString作为初始化\b的补充 1.4 BaseMailer它就厉害了，是个头，兼顾邮件发送格式内容的处理，事件发送，邮件动作等功能","link":"/2018/06/27/2018-06-27-Yii-mail%E6%A8%A1%E5%9D%97%E5%AD%A6%E4%B9%A0/"},{"title":"find,locate查找文件","text":"在使用linux时经常会不知道自己想要的文件在哪里存放着，可能会知道一个大致的位置但是却不知道精确目录和位置，这个时候搜索变得异常的方便，今天就来学学搜索命令。 find 搜索命令 这个命令是真实的遍历模式，会逐层搜索需要匹配的目标，直到搜索完毕。 12345678910111213141516171819202122232425262728293031323334353637//列出当前目录文件以及子目录的所有文件[yuekang@ykdev test]$ find .../abnc.txt//指定文件搜索[yuekang@ykdev test]$ find -name &quot;ab*&quot;./abnc.txt//忽略大小写搜索[yuekang@ykdev test]$ find -iname &quot;AB*&quot;./abnc.txt//搜索多个文件[yuekang@ykdev test]$ find . -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot;./abnc.txt./ab.pdf//匹配文件路径或文件,实际上还是匹配文件[yuekang@ykdev test]$ find . -path &quot;*yuekang*&quot;[yuekang@ykdev test]$ find . -path &quot;*ab*&quot;./abnc.txt./ab.pdf[yuekang@ykdev ~]$ find /home/ -path &quot;*yuekang*&quot;find: ‘/home/jira’: 权限不够/home/yuekang//正则匹配文件[yuekang@ykdev test]$ find . -regex &quot;.*\\(\\.txt\\|\\.pdf\\)$&quot;./abnc.txt./ab.pdf//否定查找[yuekang@ykdev test]$ find . ! -name &quot;*.pdf&quot;../abnc.txt locate 搜索命令 这个命令不搜索具体目录，而是搜索一个数据库记录（/var/lib/mlocate/mlocate.db），更新频率为每天更新，所以可能会搜索到已经删除或者搜索不到刚创建的文件，updatedb 可以完成重新刷新文件信息。 123456789101112131415161718//查找文件，当新建文件查询不到时需要手动updatedb更新本地文件数据库╭─root@ykdev /home/yuekang/test╰─# locate abnc.txt╭─root@ykdev /home/yuekang/test╰─# updatedb╭─root@ykdev /home/yuekang/test╰─# locate abnc.txt/home/yuekang/test/abnc.txt//通过regex\b 正则匹配文件root@ykdev /home/yuekang/test╰─# locate -r &quot;.*\\(\\.pdf\\)&quot;/home/yuekang/test/ab.pdf/usr/share/doc/aic94xx-firmware-30/README-94xx.pdf/usr/share/doc/bzip2-devel-1.0.6/manual.pdf/usr/share/doc/libtasn1-4.10/libtasn1.pdf/usr/share/doc/libxml2-devel-2.9.1/tutorial/xmltutorial.pdf","link":"/2018/07/04/2018-07-04-find-locate%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6/"},{"title":"CGI与FastCGI 学习","text":"CGI:是 Web Server 与 Web Application 之间数据交换的一种协议。FastCGI:同 CGI，是一种通信协议，但比 CGI 在效率上做了一些优化。PHP-CGI:是 PHP （Web Application）对 Web Server 提供的 CGI 协议的接口程序。PHP-FPM:是 PHP（Web Application）对 Web Server 提供的 FastCGI 协议的接口程序，额外还提供了相对智能一些任务管理 CGI工作流程 如果客户端请求的是 index.html，那么Web Server会去文件系统中找到这个文件，发送给浏览器，这里分发的是静态数据。 当Web Server收到 index.php 这个请求后，会启动对应的 CGI 程序，这里就是PHP的解析器。接下来PHP解析器会解析php.ini文件，初始化执行环境，然后处理请求，再以规定CGI规定的格式返回处理后的结果，退出进程，Web server再把结果返回给浏览器。 FastCGI工作流程1.如果客户端请求的是 index.html，那么Web Server会去文件系统中找到这个文件，发送给浏览器，这里分发的是静态数据。 2.当Web Server收到 index.php 这个请求后,FastCGI程序(FastCGI在启动时就初始化执行执行环境，每个CGI进程池各个CGI进程共享执行环境)在CGI进程池中选择一个CGI进程处理请求，再以规定CGI规定的格式返回处理后的结果，继续等待下一个请求。 PHP-FPM基本实现1.PHP-FPM的实现就是创建一个master进程，在master进程中创建worker pool并让其监听socket，然后fork出多个子进程(work)，这些子进程各自accept请求，子进程的处理非常简单，它在启动后阻塞在accept上，有请求到达后开始读取请求数据，读取完成后开始处理然后再返回，在这期间是不会接收其它请求的，也就是说PHP-FPM的子进程同时只能响应一个请求，只有把这个请求处理完成后才会accept下一个请求 2.PHP-FPM的master进程与worker进程之间不会直接进行通信，master通过共享内存获取worker进程的信息，比如worker进程当前状态、已处理请求数等，当master进程要杀掉一个worker进程时则通过发送信号的方式通知worker进程。 3.PHP-FPM可以同时监听多个端口，每个端口对应一个worker pool，而每个pool下对应多个worker进程 Worker工作流程1.等待请求： worker进程阻塞在fcgi_accept_request()等待请求；2.解析请求： fastcgi请求到达后被worker接收，然后开始接收并解析请求数据，直到request数据完全到达；3.请求初始化： 执行php_request_startup()，此阶段会调用每个扩展的：PHP_RINIT_FUNCTION()；4.编译、执行： 由php_execute_script()完成PHP脚本的编译、执行；5.关闭请求： 请求完成后执行php_request_shutdown()，此阶段会调用每个扩展的：PHP_RSHUTDOWN_FUNCTION()，然后进入步骤(1)等待下一个请求。","link":"/2018/07/05/2018-07-05-CGI%E4%B8%8EFastCGI-%E5%AD%A6%E4%B9%A0/"},{"title":"CentOS7 安装OpenLdap","text":"正常在企业的环境中，会遇到账户统一管理的事情，当手下就不几台服务器时在每个机器上都创建一遍好像也没多大事事情，但当人经常更换，或者服务器达到上百台的时候这个账号的管理将会是噩梦，今天就来一起安装OpenLdap来达到网络统一账号管理和验证的目的。 什么是LDAP?LDAP 全称轻量级目录访问协议（英文：Lightweight Directory Access Protocol），是一个运行在 TCP/IP 上的目录访问协议。目录是一个特殊的数据库，它的数据经常被查询，但是不经常更新。其专门针对读取、浏览和搜索操作进行了特定的优化。目录一般用来包含描述性的，基于属性的信息并支持精细复杂的过滤能力。比如 DNS 协议便是一种最被广泛使用的目录服务。 LDAP 中的信息按照目录信息树结构组织，树中的一个节点称之为条目（Entry），条目包含了该节点的属性及属性值。条目都可以通过识别名 dn 来全局的唯一确定1，可以类比于关系型数据库中的主键。比如 dn 为 uid=teddy,ou=People,dc=ethercap,dc=com 的条目表示在组织中一个名字叫做 teddy 的员工，其中 uid=teddy 也被称作相对区别名 rdn。 属性名 是否必填 描述 cn 是 该条目被人所熟知的通用名（Common Name） sn 是 该条目的姓氏 o 否 该条目所属的组织名（Organization Name） mobile 否 该条目的手机号码 description 否 该条目的描述信息 \b下面是一个典型的 LDAP 目录树结构，其中每个节点表示一个条目。接下来将按照这个结构来配置一个 LDAP 服务。 LDAP server搭建 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980//安装软件yum -y install openldap openldap-servers openldap-clients//配置/etc/openldap/slapd.confinclude /etc/openldap/schema/core.schemainclude /etc/openldap/schema/cosine.schemainclude /etc/openldap/schema/duaconf.schemainclude /etc/openldap/schema/dyngroup.schemainclude /etc/openldap/schema/inetorgperson.schemainclude /etc/openldap/schema/java.schemainclude /etc/openldap/schema/misc.schemainclude /etc/openldap/schema/nis.schemainclude /etc/openldap/schema/openldap.schemainclude /etc/openldap/schema/ppolicy.schemainclude /etc/openldap/schema/collective.schemapidfile /var/run/openldap/slapd.pidargsfile /var/run/openldap/slapd.argsdatabase bdbsuffix &quot;dc=hostname,dc=com&quot;rootdn &quot;cn=ffff,dc=hostname,dc=com&quot;rootpw esdfdsf//数据会存放到/var/openldap-data/ 中//id2entry.bdb 一开始会没有，使用\bJXplorer即可自动生成这个文件// 记得/var/openldap-data/DB_CONFIGcp /usr/share/openldap-servers/DB_CONFIG.example /var/openldap-data/DB_CONFIG//加入到service管理体系中systemctl enable slapdsystemctl start slapd//导入用户组dn: dc=ethercap,dc=comobjectClass: topobjectClass: dcObjectobjectclass: organizationo: Server Worlddc: ethercapdn: ou=people,dc=ethercap,dc=comobjectClass: organizationalUnitou: peopledn: ou=groups,dc=ethercap,dc=comobjectClass: organizationalUnitou: groups\bldapadd -Y EXTERNAL -H ldapi:/// -f front.ldif//\b添加用户cat /etc/passwd | grep yk &gt; /tmp/passwd.in/usr/share/migrationtools/migrate_passwd.pl /tmp/passwd.in &gt; /tmp/passwd.ldif//发现dc不对，可以通过 修改vi /usr/share/migrationtools/migrate_common.ph$DEFAULT_BASE = &quot;dc=ethercap,dc=com&quot;;//查看生成文件，没什么毛病dn: uid=yk,ou=People,dc=ethercap,dc=comuid: ykcn: ykobjectClass: accountobjectClass: posixAccountobjectClass: topobjectClass: shadowAccountuserPassword: {crypt}$1$eZc1Mzdw$HBvCDOC1KEWIO699dLCNl1shadowLastChange: 17722shadowMin: 0shadowMax: 99999shadowWarning: 7loginShell: /bin/bashuidNumber: 1001gidNumber: 1001homeDirectory: /home/yk//导入用户到ldapldapadd -x -D &quot;cn=admin,dc=ethercap,dc=com&quot; -W -f /tmp/passwd.ldif 导入后的效果 LdapClient 客户端配置12345678910111213141516171819202122232425262728293031323334353637383940//安装客户端必备软件yum install -y oddjob-mkhomedir oddjob openssh-ldap//开启相关配置选项 /etc/sysconfig/authconfigUSELDAP=yes USELDAPAUTH=yes USEMD5=no USESHADOW=yes USELOCAUTHORIZE=yes//配置ldap /etc/openldap/ldap.confURI ldap://URL/BASE dc=ethercap,dc=comBINDDN cn=admins//配置centos验证方式/etc/nsswitch.conf文件,修改为ldap验证passwd: files ldapshadow: files ldapgroup: files ldap//加入到service管理chkconfig oddjobd on//启动服务service messagebus startservice oddjobd start//启用自动创建目录authconfig --enablemkhomedir --update//修改ssdh加入命令 \b两条都得有缺一不可！AuthorizedKeysCommand /usr/libexec/openssh/ssh-ldap-wrapperAuthorizedKeysCommandUser root//手动添加/etc/pam.d/password-auth和system-authsession optional pam_oddjob_mkhomedir.so umask=0077//重启服务 生效配置service nslcd restartservice sshd restart \b采坑总结，自动家目录创建依靠pam_oddjob_mkhomedir.so来实现，\b前期,使用之前确保oddjobd 是运行状态,否则报错！ 12345678yk@dev:~$ service oddjobd statusRedirecting to /bin/systemctl status oddjobd.service● oddjobd.service - privileged operations for unprivileged applications Loaded: loaded (/usr/lib/systemd/system/oddjobd.service; enabled; vendor preset: disabled) Active: active (running) since 三 2018-07-11 17:37:39 CST; 4h 59min ago Main PID: 15108 (oddjobd) CGroup: /system.slice/oddjobd.service └─15108 /usr/sbin/oddjobd -n -p /var/run/oddjobd.pid -t 300 修改sshd_config重启后报错，单纯查看状态无法知道错误信息，可以通过下面的命令查看 1`which sshd` -D -d","link":"/2018/07/08/2018-07-08-CentOS7-%E5%AE%89%E8%A3%85OpenLdap/"},{"title":"负载均衡算法","text":"本地流量管理技术主要有一下几种负载均衡算法 静态负载均衡算法包括：轮询，比率，优先权 1.1 轮询（Round Robin）：顺序循环将请求一次顺序循环地连接每个服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从顺序循环队列中拿出，不参加下一次的轮询，直到其恢复正常。 1.2 比率（Ratio）：给每个服务器分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。 1.3 优先权（Priority）：给所有服务器分组,给每个组定义优先权，BIG-IP 用户的请求，分配给优先级最高的服务器组（在同一组内，采用轮询或比率算法，分配用户的请求）；当最高优先级中所有服务器出现故障，BIG-IP 才将请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。 动态负载均衡算法包括: 最少连接数,最快响应速度，观察方法，预测法，动态性能分配，动态服务器补充，服务质量，服务类型，规则模式。 2.1 最少的连接方式（Least Connection）：传递新的连接给那些进行最少连接处理的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。 2.2 最快模式（Fastest）：传递连接给那些响应最快的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。 2.3 观察模式（Observed）：连接数目和响应时间以这两项的最佳平衡为依据为新的请求选择服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。 2.4 预测模式（Predictive）：BIG-IP利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。(被BIG-IP 进行检测) 2.5 动态性能分配(Dynamic Ratio-APM):BIG-IP 收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。 2.6 动态服务器补充(Dynamic Server Act.):当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。 2.7 服务质量(QoS）:按不同的优先级对数据流进行分配。 2.8 服务类型(ToS): 按不同的服务类型（在Type of Field中标识）负载均衡对数据流进行分配。 2.9 规则模式：针对不同的数据流设置导向规则，用户可自行。","link":"/2018/07/15/2018-07-15-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"title":"proxy 反向代理设置","text":"在公司的vpc网络中需要一个统一的对外提供服务的服务器叫proxy 其作用是统一入口，外界无法直接和业务服务器直接通信，而是通过proxy服务器进行服务转发。 目标是达到如下目的：客户端=&gt;（服务器反向代理=&gt;）Web服务器 线上proxy配置 123456789101112131415161718192021server { listen 443 ssl; server_name abc.ethercap.com; ssl on; ssl_certificate /etc/pki/CA/certs/ethercap.com.chained.crt; ssl_certificate_key /etc/pki/CA/certs/ethercap.com.key; keepalive_timeout 60; location / { proxy_pass http://base_server; proxy_http_version 1.1; proxy_set_header Host $host; proxy_set_header Connection &quot;&quot;; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header X-Forwarded-Proto https; proxy_redirect off; } } 关键点是 proxy_pass proxy_pass 可以做的几件事是这样的: 本地不处理，交给后面处理这样后面就可以用php, fastcgi, tomcat等处理可以切换协议，比如从http切换至https实际上在linux上还可以将底层切换至unix domain socket // 这些设置主要是给业务服务器做认证的proxy_http_version 1.1; //这个proxy_set_header Host $host; $host就是nginx代理服务器，也就是客户端请求的hostproxy_set_header Host $host; //任何逐段传输头都需要在 Connection 头中列出，这样才能让第一个代理知道必须处理它们且不转发这些头proxy_set_header Connection “”; //X-Forwarded-For 表示 Nginx 接收到的头，原样的转发过来（假如不转发，Web 服务器就不能获取这个头）proxy_set_header X-Forwarded-For $remote_addr; //转发的协议proxy_set_header X-Forwarded-Proto https;","link":"/2018/07/15/2018-07-15-proxy-%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE/"},{"title":"jumperServer","text":"JumpeServer 是用Python+Django开发的跳板机及堡垒机于一身的开源项目，并通过与OpenLDAP的结合可对服务器实现Web端账号、密码管理、权限管理、主机管理，并实现Web端监控和审计，提供上传文件的功能。其主要功能有以下几个。 用户管理（认证） 资产管理 授权管理（授权） 监控审计（审计） 文件上传 JumperServer \b由以下部分组成 官方网站：https://jumpserver.readthedocs.io/zh/docs/snapshot.html","link":"/2018/07/22/2018-07-22-jumperServer/"},{"title":"saltStack 搭建","text":"SaltStack是一个服务器基础架构集中化管理平台，具备配置管理、远程执行、监控等功能，一般可以理解为简化版的puppet和加强版的func。SaltStack基于Python语言实现，结合轻量级消息队列（ZeroMQ）与Python第三方模块（Pyzmq、PyCrypto、Pyjinjia2、python-msgpack和PyYAML等）构建。通过部署SaltStack环境，我们可以在成千上万台服务器上做到批量执行命令，根据不同业务特性进行配置集中化管理、分发文件、采集服务器数据、操作系统基础及软件包管理等，SaltStack是运维人员提高工作效率、规范业务配置与操作的利器。 组成形式 配置文件从top.sls为入口，这里面定义所有文件信息。 基础环境搭建服务端安装脚本12curl -L https://bootstrap.saltstack.com -o install_salt.shsudo sh install_salt.sh -P -M 客户端安装脚本12curl -L https://bootstrap.saltstack.com -o install_salt.shsudo sh install_salt.sh -P \b 指定-P 代表着 master 安装 基础环境配置服务端1234567891011121314151617181920vi /etc/salt/master//配置主服务器地址interface: 192.168.1.192//以哪个用户运行user: root//指定salt配置路径file_roots: base: - /root/saltstack/salt/base prod: - /root/saltstack/salt/prod//环境配置文件pillar_roots: base: - /root/saltstack/pillar/base 客户端配置12345678vi /etc/salt/minion//指定主服务器ipmaster: 192.168.1.192//指定机器ID 不要重名！ id: salt_slave_01 此刻就配置完毕，进入调试连接部分 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209//打开客户端的debug模式(注意，必须关闭salt-minion服务，否则会提示端口占用，debug模式单独跑的！调试完毕以后在启动salt-minion服务)root@salt_slave_01:~# salt-minion -l debug//进入master，查看授权列表[root@localhost ~]# salt-key -LAccepted Keys: //同意的keyDenied Keys: //拒绝的keyUnaccepted Keys: //未接受的keysalt_slave_01salt_slave_02Rejected Keys: //被拒绝的key//可以看到已经\b有两个minion请求\b授权了//授权主机[root@localhost ~]# salt-key -a salt_slave1//全部授权[root@localhost ~]# salt-key -A//授权结束以后就完成了master和minion的连接动作//测试和子节点的连通性[root@localhost ~]# salt '*' test.pingsalt_slave_01: Truesalt_slave_02: True//安装配置文件中的服务，并同步所有配置文件数据salt '*' sate.highstate``至此完成全部salt软件安装服务# 命令附录```shell***********模块***********查看模块列表modulesalt 'minion' sys.list_modules查看指定module的function用法salt 'minion' sys.list_functions file查看指定模块的详细用法salt 'minion' sys.doc cmd***********模块使用说明***********查看配置管理state模块列表salt 'minion' sys.list_state_modules查看配置管理sate列表指定模块所有方法列表salt 'minion' sys.list_state_functions svn查看配置管理state列表指定模块详细用法salt 'minion' sys.state_doc file查看配置管理state列表指定模块的方法分支salt 'minion' sys.state_doc file.managed***********pillar变量***********查看主机对应的所有pillar变量值salt '*' pillar.datasalt '*' pillar.items查看主机对应的多个pillar变量值salt '*' pillar.item roles appname修改pillar值后需要刷新pillar数据salt '*' saltutil.refresh_pillar查看pillar模块详细用法,其他类似salt 'minion' sys.doc pillar查看pillar的相关方法salt 'minion' sys.list_functions pillar&quot;&quot;&quot;shuke: - pillar.data - pillar.ext - pillar.get - pillar.item - pillar.items - pillar.raw&quot;&quot;&quot;***********grains变量***********查看模块用法salt 'minion' sys.list_functions grains查看item项salt 'minion' grains.ls查看所有iteamssalt 'minion' grains.items获得某个item值salt 'minion' grains.get os同步_grains目录下的py脚本至minionsalt 'minion' saltutil.sync_all如果py模块有修改,修改后进行重载salt 'minion' sys.reload_modules***********minions在线状态***********查看所有minion状态salt-run manage.status查看所有minion在线状态salt-run manage.up查看所有minion不在线状态salt-run manage.down***********key管理***********salt-key 密钥管理，通常在master端执行salt-key [options]salt-key -L ##查看所有minion-keysalt-key -a &lt;key-name&gt; ##接受某个minion-keysalt-key -d &lt;key-name&gt; ##删除某个minion-keysalt-key -A ##接受所有的minion-keysalt-key -D ##删除所有的minion-key***********salt-call相关***********salt-call 该命令通常在minion上执行，minion自己执行可执行模块，不是通过master下发jobsalt-call [options] &lt;function&gt; [arguments]salt-call test.ping ##自己执行test.ping命令salt-call cmd.run 'ifconfig' ##自己执行cmd.run函数***********文件分发***********salt-cp 分发文件到minion上,不支持目录分发，通常在master运行salt-cp [options] '&lt;target&gt;' SOURCE DESTsalt-cp '*' testfile.html /tmpsalt-cp 'test*' index.html /tmp/a.htmlsalt 'S1_0_001_Room' cp.get_dir salt://package /tmp -v 同步目录salt 'S1_0_001_Room' cp.get_file salt://package/minions.tar.gz /tmp/minions.tar.gz gzip=5 同步文件**********其他***********salt-run jobs.active #查看所有minion当前正在运行的jobssalt '*' saltutil.running # 查看正在运行的任务，找到jidsalt '*' saltutil.kill_job jid # 根据jid杀掉任务salt '*' saltutil.clear_cache # 清除minion缓存执行单个命令salt 'minion' cmd.run 'ps -ef | grep mongod'测试单个sls模块salt 'minion' state.sls nginx test=True执行前进行测试salt 'minion' state.highstate test=True在所有minion上执行状态:salt 'minion' sate.highstate获取执行jib任务的md5值salt 'minion' hashutil.md5_digest 20170202150211366486low数据可以使用state.show_lowstate方法查看salt 'minion' state.show_lowstate --out yamlHigh State数据可以使用state.show_hoghstate方法查看salt 'minion' state.show_highstate --out yaml#查看highstatesalt 'minion' state.show_highstate#查看lowdatasalt 'minion' state.show_lowstate#执行所有top.slssalt '*' state.apply#执行指定环境下top.slssalt '*' state.apply saltenv=dev注:name：要执行的命令，记住该命令将会在salt-minion的路径和权限下执行onlyif：用于检查的命令，仅当``onlyif``选项指向的命令返回true时才执行name定义的命令unless：用于检查的命令，仅当``unless``选项指向的命令返回false时才执行name指向的命令查看wyd用户下进程salt -N 'Z1_S2' cmd.run 'su -c &quot;ps -u wyd | grep -v top | grep -v bash | grep -v sshd | grep -v grep | grep -v ps | grep -v CMD &quot; wyd'state中(钩子函数)requisiterequisite:require/watch/onchanges/onfail/use/prereq/require_in(反转)========Targeting Minion=======#Glob(默认)salt '*' test.pingsalt \\* test.ping#PCRE 正则表达式salt -E '^[m|M]in.[e|o|u]n$' test.ping = salt -E '^[mM]in.[eou]n$' test.ping#listsalt -L web1,web2,db1 test.ping#Subnetsalt -S 192.168.1.100 test.pingsalt -S 192.168.0.0/16 test.ping#Grainsalt -G 'os:ubuntu' test.pingsalt -G 'os_family:Debian' test.pingsalt -G 'ip_interfaces:eth0:192.168.1.100' test.pingsalt -G 'ipv6:::1' test.pingsalt --grain-pcre 'os:red(hat|flag)' test.ping#Pillarsalt -I 'my_var:my_val' test.ping#混合(Compound)salt -C 'G@os:Ubuntu,I@role:web,S@192.168.1.100/24' test.pingsalt -C 'min* or *ion' test.pingsalt -C 'web* or *qa,G@os:Arch' test.ping#Nodegroupsalt -N webdev test.ping添加计划任务salt 'S1_*_Center' cron.set_job root '0' '5' '*' '*' '*' '/usr/sbin/logrotate -vf /etc/logrotate.d/acl &gt;/tmp/cutacl_log 2&gt;&amp;1' identifier=cutacl删除计划任务salt -C 'E@S1_(10001|10002|10003)_*' cron.rm_job wyd 'cd /data/wyd/game_server_1.2.0/log;find . -type f -mtime +15 -name &quot;*.log*&quot; -exec rm -rf {} \\; 2&gt;&amp;1' identifier='clear log'","link":"/2018/07/30/2018-07-30-saltStack-%E6%90%AD%E5%BB%BA/"},{"title":"Zend虚拟机学习","text":"Zend虚拟机（\bZend VM）是PHP语言的核心，承担了语法和词法分析、AST变异以及指令的执行工作。 Zend虚拟机架构 解释层 这一层主要负责对PHP代码进行\b词法和语法分析，生成对应的AST。另一个工作\b就是对AST进行编译，生成符号表和指令集。 中间数据层 这一层主要包含了虚拟机的核心部分–执行栈的维护、指令集和符号表的存储，而这些是执行引擎调度执行的基础。 执行层 这一层是执行命令集的引擎，负责最终的执行并生成结果，这一层实现了大量的底层函数。","link":"/2018/08/05/2018-08-05-Zend%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AD%A6%E4%B9%A0/"},{"title":"SaltStack知识整理","text":"上一篇说到了salt的简单安装，接下来将对学习salt相关模块进行整理和学习 GrainsGrains是存储minion基本信息的，里面存放了\bminion端各种系统级参数，采用静态采集方式，在minion启动时进行数据采集。可以通过salt '*' saltutil.sync_grains 从新进行\bminion端静态信息的采集. 展示minion的Grains静态信息 salt '*' grains.items 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287newdev: ---------- SSDs: - sda - dm-0 - dm-1 - dm-2 biosreleasedate: 05/21/2018 biosversion: 13.3.1 (43365) cpu_flags: - fpu - vme - de - pse - tsc - msr - pae - mce - cx8 - apic - sep - mtrr - pge - mca - cmov - pat - pse36 - clflush - mmx - fxsr - sse - sse2 - ss - ht - syscall - nx - rdtscp - lm - constant_tsc - nopl - xtopology - nonstop_tsc - eagerfpu - pni - pclmulqdq - ssse3 - fma - cx16 - pcid - sse4_1 - sse4_2 - x2apic - movbe - popcnt - tsc_deadline_timer - aes - xsave - avx - f16c - rdrand - hypervisor - lahf_lm - abm - 3dnowprefetch - fsgsbase - tsc_adjust - bmi1 - hle - avx2 - smep - bmi2 - invpcid - mpx - adx - clflushopt - xsaveopt - dtherm - arat - pln - pts cpu_model: Intel(R) Core(TM) i5-7360U CPU @ 2.30GHz cpuarch: x86_64 disks: - sr0 dns: ---------- domain: ip4_nameservers: - 192.168.1.1 ip6_nameservers: nameservers: - 192.168.1.1 options: search: - lan sortlist: domain: fqdn: salt_salve_2 fqdn_ip4: - 192.168.1.145 fqdn_ip6: - fe80::d0f:e7bc:6a7f:a752 gid: 0 gpus: |_ ---------- model: Accelerated Virtual Video Adapter vendor: unknown groupname: root host: salt_salve_2 hwaddr_interfaces: ---------- eth0: 00:1c:42:bb:de:e6 lo: 00:00:00:00:00:00 id: newdev init: systemd ip4_gw: 192.168.1.1 ip4_interfaces: ---------- eth0: - 192.168.1.145 lo: - 127.0.0.1 ip6_gw: False ip6_interfaces: ---------- eth0: - fe80::d0f:e7bc:6a7f:a752 lo: - ::1 ip_gw: True ip_interfaces: ---------- eth0: - 192.168.1.145 - fe80::d0f:e7bc:6a7f:a752 lo: - 127.0.0.1 - ::1 ipv4: - 127.0.0.1 - 192.168.1.145 ipv6: - ::1 - fe80::d0f:e7bc:6a7f:a752 kernel: Linux kernelrelease: 3.10.0-862.el7.x86_64 kernelversion: #1 SMP Fri Apr 20 16:44:24 UTC 2018 locale_info: ---------- defaultencoding: UTF-8 defaultlanguage: en_US detectedencoding: UTF-8 localhost: salt_salve_2 lsb_distrib_codename: CentOS Linux 7 (Core) lsb_distrib_id: CentOS Linux machine_id: 4759594b77c0c04fb629ee0b4da6fdbe manufacturer: Parallels Software International Inc. master: 192.168.1.194 mdadm: mem_total: 1222 nodename: localhost.localdomain num_cpus: 2 num_gpus: 1 os: CentOS os_family: RedHat osarch: x86_64 oscodename: CentOS Linux 7 (Core) osfinger: CentOS Linux-7 osfullname: CentOS Linux osmajorrelease: 7 osrelease: 7.5.1804 osrelease_info: - 7 - 5 - 1804 path: /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin pid: 24821 productname: Parallels Virtual Platform ps: ps -efHww pythonexecutable: /usr/bin/python pythonpath: - /usr/bin - /usr/lib64/python27.zip - /usr/lib64/python2.7 - /usr/lib64/python2.7/plat-linux2 - /usr/lib64/python2.7/lib-tk - /usr/lib64/python2.7/lib-old - /usr/lib64/python2.7/lib-dynload - /usr/lib64/python2.7/site-packages - /usr/lib/python2.7/site-packages pythonversion: - 2 - 7 - 5 - final - 0 saltpath: /usr/lib/python2.7/site-packages/salt saltversion: 2018.3.2 saltversioninfo: - 2018 - 3 - 2 - 0 selinux: ---------- enabled: True enforced: Enforcing serialnumber: Parallels-4B 59 59 47 C0 77 4F C0 B6 29 EE 0B 4D A6 FD BE server_id: 2082849409 shell: /bin/bash swap_total: 2047 systemd: ---------- features: +PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 -SECCOMP +BLKID +ELFUTILS +KMOD +IDN version: 219 uid: 0 username: root uuid: 4759594b-77c0-c04f-b629-ee0b4da6fdbe virtual: Parallels zfs_feature_flags: False zfs_support: False zmqversion: 4.1.4 \b# Pillar Pillar主要用于master端分发给minion端的信息，针对于Grains不同的是它是动态加密传输的，而且只有指定minion才能收到这些pillar信息。 通过salt '*' pillar.items \b来展示pillar信息，通过salt '*' saltutil.refresh_pillar 来刷新pillar信息。 12345678910111213newdev: ---------- groups: |_ ---------- name: dev nodes: - dev - newdev sshd_port: 22 High State 与 Low State如果什么配置都没问题以后可以通过 salt '*' state.highstate 完成所有机器的部署动作。","link":"/2018/08/09/2018-08-09-SaltStack%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/"},{"title":"HAProxy搭建","text":"HAProxy是一个免费的负载均衡软件，可以运行于大部分主流的Linux操作系统上。 HAProxy提供了L4(TCP)和L7(HTTP)两种负载均衡能力，具备丰富的功能。HAProxy的社区非常活跃，版本更新快速（最新稳定版1.7.2于2017/01/13推出）。最关键的是，HAProxy具备媲美商用负载均衡器的性能和稳定性。 因为HAProxy的上述优点，它当前不仅仅是免费负载均衡软件的首选，更几乎成为了唯一选择。 HAProxy的核心功能负载均衡：L4和L7两种模式，支持RR/静态RR/LC/IP Hash/URI Hash/URL_PARAM Hash/HTTP_HEADER Hash等丰富的负载均衡算法健康检查：支持TCP和HTTP两种健康检查模式会话保持：对于未实现会话共享的应用集群，可通过Insert Cookie/Rewrite Cookie/Prefix Cookie，以及上述的多种Hash方式实现会话保持SSL：HAProxy可以解析HTTPS协议，并能够将请求解密为HTTP后向后端传输HTTP请求重写与重定向监控与统计：HAProxy提供了基于Web的统计信息页面，展现健康状态和流量数据。基于此功能，使用者可以开发监控程序来监控HAProxy的状态","link":"/2018/09/25/2018-09-25-HAProxy%E6%90%AD%E5%BB%BA/"},{"title":"KeepAlived搭建","text":"Keepalived是一个用C语言编写的路由软件。该项目的主要目标是为Linux系统和基于Linux的基础架构提供简单而强大的负载均衡和高可用性设施。 负载平衡框架依赖于众所周知且广泛使用的Linux虚拟服务器（IPVS）内核模块，提供Layer4负载均衡。Keepalived实现了一组检查程序，以根据其运行状况动态地和自适应地维护和管理负载均衡的服务器池。另一方面，VRRP实现了高可用性 协议。VRRP是路由器故障转移的基础。此外，Keepalived为VRRP有限状态机实现了一组挂钩，提供低级和高速协议交互。Keepalived框架可以单独使用，也可以一起使用，以提供灵活的基础架构。 软件安装KeepAlived官网：http://www.keepalived.org/ 123456789//下载包[root@rabbitmq-master ~]# wget http://www.keepalived.org/software/keepalived-2.0.7.tar.gz[root@rabbitmq-master ~]# tar -zxvf keepalived-2.0.7.tar.gz[root@rabbitmq-master ~]# cd keepalived-2.0.7//统一放到/usr/local/keepalived[root@rabbitmq-master keepalived-2.0.7]#/configure --prefix=/usr/local/keepalived[root@rabbitmq-master keepalived-2.0.7]# make &amp;&amp; make install 配置KeepAlive配置目录 12345678910111213141516171819202122232425262728293031323334353637[root@rabbitmq-master keepalived]# tree etc/etc/├── keepalived│ ├── keepalived.conf│ └── samples│ ├── client.pem│ ├── dh1024.pem│ ├── keepalived.conf.conditional_conf│ ├── keepalived.conf.fwmark│ ├── keepalived.conf.HTTP_GET.port│ ├── keepalived.conf.inhibit│ ├── keepalived.conf.IPv6│ ├── keepalived.conf.misc_check│ ├── keepalived.conf.misc_check_arg│ ├── keepalived.conf.quorum│ ├── keepalived.conf.sample│ ├── keepalived.conf.SMTP_CHECK│ ├── keepalived.conf.SSL_GET│ ├── keepalived.conf.status_code│ ├── keepalived.conf.track_interface│ ├── keepalived.conf.virtualhost│ ├── keepalived.conf.virtual_server_group│ ├── keepalived.conf.vrrp│ ├── keepalived.conf.vrrp.localcheck│ ├── keepalived.conf.vrrp.lvs_syncd│ ├── keepalived.conf.vrrp.routes│ ├── keepalived.conf.vrrp.rules│ ├── keepalived.conf.vrrp.scripts│ ├── keepalived.conf.vrrp.static_ipaddress│ ├── keepalived.conf.vrrp.sync│ ├── root.pem│ ├── sample.misccheck.smbcheck.sh│ └── sample_notify_fifo.sh└── sysconfig └── keepalived3 directories, 30 files 分别对应系统目录 123/etc/keepalived/keepalived.conf/etc/rc.d/init.d/keepalived/etc/sysconfig/keepalived 可能遇到的错误 缺少编译环境 需要安装编译环境 1[root@rabbitmq-slave keepalived-2.0.7]# yum install gcc -y 缺少openssl组件 安装openssl组件 1[root@rabbitmq-slave keepalived-2.0.7]# yum -y install openssl-devel 找不到path/to/keepalived/etc/rd.d 怎么办? \b编译的时候缺少安装","link":"/2018/09/29/2018-09-29-KeepAlived%E6%90%AD%E5%BB%BA/"},{"title":"Centos7上搭建统一认证服务","text":"一个企业经常会碰上部署多台机器的问题，但是账号管理就成了问题，怎么在N台机器上统一部署账号管理，完成账号统一认证和管理是让我们后续非常方便的地方。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111//安装三大应用，服务端，客户端，导出导入工具yum install -y openldap-servers openldap-clients migrationtools//配置文件cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIGchown ldap. /var/lib/ldap/DB_CONFIG//启动服务systemctl start slapdsystemctl enable slapd//生成root密码╭─root@ykdev ~╰─# slappasswdNew password:Re-enter new password:{SSHA}/UFZ8EehpMMtKiiAy+vxdxH6fObhaF3l//修改rootdn密码cat chrootpw.ldifdn: olcDatabase={0}config,cn=configchangetype: modifyadd: olcRootPWolcRootPW: {SSHA}/UFZ8EehpMMtKiiAy+vxdxH6fObhaF3lldapadd -Y EXTERNAL -H ldapi:/// -f chrootpw.ldif//导出基础的Schema，这些 Schema 文件位于 /etc/openldap/schema/ 目录中，定义了我们以后创建的条目可以使用哪些属性[root@localhost ~]# ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldif SASL/EXTERNAL authentication startedSASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=authSASL SSF: 0adding new entry &quot;cn=cosine,cn=schema,cn=config&quot;[root@localhost ~]# ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldif SASL/EXTERNAL authentication startedSASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=authSASL SSF: 0adding new entry &quot;cn=nis,cn=schema,cn=config&quot;[root@localhost ~]# ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif SASL/EXTERNAL authentication startedSASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=authSASL SSF: 0adding new entry &quot;cn=inetorgperson,cn=schema,cn=config&quot;//配置 LDAP 的顶级域[root@proxy ldap]# cat chdomain.ldifdn: olcDatabase={1}monitor,cn=configchangetype: modifyreplace: olcAccessolcAccess: {0}to * by dn.base=&quot;gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth&quot; read by dn.base=&quot;cn=Manager,dc=my-domain,dc=com&quot; read by * nonedn: olcDatabase={2}hdb,cn=configchangetype: modifyreplace: olcSuffixolcSuffix: dc=my-domain,dc=comdn: olcDatabase={2}hdb,cn=configchangetype: modifyreplace: olcRootDNolcRootDN: cn=Manager,dc=my-domain,dc=comdn: olcDatabase={2}hdb,cn=configchangetype: modifyreplace: olcRootPWolcRootPW: {SSHA}/UFZ8EehpMMtKiiAy+vxdxH6fObhaF3ldn: olcDatabase={2}hdb,cn=configchangetype: modifyadd: olcAccessolcAccess: {0}to attrs=userPassword,shadowLastChange by dn=&quot;cn=Manager,dc=my-domain,dc=com&quot; write by anonymous auth by self write by * noneolcAccess: {1}to dn.base=&quot;&quot; by * readolcAccess: {2}to * by dn=&quot;cn=Manager,dc=my-domain,dc=com&quot; write by * read[root@localhost ~]# ldapmodify -Y EXTERNAL -H ldapi:/// -f chdomain.ldif //导入基础组信息什么的[root@proxy ldap]# cat base.ldifdn: dc=my-domain,dc=comdc: my-domainobjectClass: topobjectClass: domaindn: ou=People,dc=my-domain,dc=comou: PeopleobjectClass: topobjectClass: organizationalUnitdn: ou=Group,dc=my-domain,dc=comou: GroupobjectClass: topobjectClass: organizationalUnitldapadd -x -D &quot;cn=Manager,dc=my-domain,dc=com&quot; -W -f base.ldif//导入用户信息//修改域名基础信息vi /usr/share/migrationtools/migrate_common.ph$DEFAULT_BASE = &quot;dc=my-domain,dc=com&quot;;[root@proxy ldap]# /usr/share/migrationtools/migrate_passwd.pl /etc/passwd passwd.ldif[root@proxy ldap]# /usr/share/migrationtools/migrate_group.pl /etc/group group.ldif[root@proxy ldap]# ldapadd -x -D cn=Manager,dc=my-domain,dc=com -W -f passwd.ldif[root@proxy ldap]# ldapadd -x -D cn=Manager,dc=my-domain,dc=com -W -f group.ldif//查看所有记录[root@proxy ldap]# ldapsearch -x -b &quot;dc=my-domain,dc=com&quot; -H ldap://192.168.1.1 至此全部搭建完毕","link":"/2018/10/24/2018-10-24-Centos7%E4%B8%8A%E6%90%AD%E5%BB%BA%E7%BB%9F%E4%B8%80%E8%AE%A4%E8%AF%81%E6%9C%8D%E5%8A%A1/"},{"title":"ZooKeeper集群化安装","text":"zookeeper是一个强一致【不严格】的分布式数据库，由多个节点共同组成一个分布式集群，挂掉任意一个节点，数据库仍然可以正常工作，客户端无感知故障切换。客户端向任意一个节点写入数据，其它节点可以立即看到最新的数据。 布局规划图 环境准备 JRE (依赖的环境)【 点击进入 】 安装JRE 12345678910111213tar zxvf jre-8u191-linux-x64.tar.gzmv jre1.8.0_191/ /opt///添加环境变量vi /etc/profile//末尾加入JAVA_HOME=/opt/jre1.8.0_191PATH=$JAVA_HOME/bin:$PATHCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport JAVA_HOMEexport PATHexport CLASSPATH//生效配置source /etc/profile \b开启端口 默认是2181 我自己设定为2999，2888和3888是机器之间同步端口 1234firewall-cmd --zone=public --add-port=2999/tcp --permanentfirewall-cmd --zone=public --add-port=2888/tcp --permanentfirewall-cmd --zone=public --add-port=3888/tcp --permanentfirewall-cmd --reload ZooKeeper安装包 12345wget http://mirror.cogentco.com/pub/apache/zookeeper/zookeeper-3.4.13/zookeeper-3.4.13.tar.gztar zxvf zookeeper-3.4.13.tar.gzmv zookeeper-3.4.13 /opt/ 安装配置ZooKeeper 基础环境安装完成后，需要配置\bZooKeeper 1234//配置cp /opt/zookeeper-3.4.13/conf/zoo_sample.cfg /opt/zookeeper-3.4.13/conf/zoo.cfgvi /opt/zookeeper-3.4.13/conf/zoo.cfg 有以下配置选项 tickTime=2000 最小时间单元长度，默认3000，例如回话的最小超时时间默认2*tickTIme initLimit=5 默认：10，定义leader服务在启动过程中等待follower完成数据同步的时间，后续服务器增多需要增大这个值，以保证数据同步顺利完成。 dataDir=/var/lib/zookeeper/ 无默认，必须配置，用于配置ZooKeeper存放快照文件的目录，如果不配置dataLogDir则也存放在这里面。 clientPort=2999 当前服务对外的端口，集群内服务器都可以配置任意可用端口，\b不需要保持端口一致！一般是2181， 无默认，必须配置！ server.1 = server1:2888:3888 用于定义整个集群是由那几台机器构成的，每一行代表一个机器配置格式如下： server.id = host:localPort:targetPort 创建myid文件标识当前主机的序号，在dataDir中新建 12vi /var/lib/zookeeper/myid写上当前主机的序号即可，一定要是整数！ 启动ZooKeeper 1234/opt/zookeeper-3.4.13/bin/zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfgStarting zookeeper ... STARTED 看到上方标识意味启动成功 验证\u001dZooKeeper服务123456789101112131415161718[root@zookeepermaster bin]# telnet localhost 2999Trying ::1...Connected to localhost.Escape character is '^]'.statZookeeper version: 3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMTClients: /0:0:0:0:0:0:0:1:56564[0](queued=0,recved=1,sent=0)Latency min/avg/max: 0/0/0Received: 1Sent: 0Connections: 1Outstanding: 0Zxid: 0x200000000Mode: followerNode count: 4Connection closed by foreign host. 像上方这样的返回意味着已经成功运行ZooKeeper了，其中Mode: follower是当前的身份 Mode: leader leader 是节点中选举的主节点整个服务器中就1个 Mode: follower follower 是从节点，负责服务客户端 Mode: standalone standalone 是单机模式下才会有的 采坑集结如果telnet验证时返回下面这样的情况 1234567[root@zookeepermaster bin]# telnet 127.0.0.1 2999Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is '^]'.statThis ZooKeeper instance is not currently serving requestsConnection closed by foreign host. 碰到上面的情况首先应该检查各个服务节点的机器是否端口已经全部打开？,主要原因就是这个节点无法连接其他服务器造成服务无法选举造成了服务出错","link":"/2018/11/05/2018-11-05-ZooKeeper%E9%9B%86%E7%BE%A4%E5%8C%96%E5%AE%89%E8%A3%85/"},{"title":"php安装ZooKeeper","text":"上一篇说了zookeeper的搭建，现在就得在php环境中使用上它，&quot;ZooKeeper&quot;是Java开发的对java支持比较好，如果php想使用上必须安装其c扩展才可以使用 一、基础环境软件包准备 Lib Zookeeper包下载地址： http://zookeeper.apache.org/releases.html 1wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.13/zookeeper-3.4.13.tar.gz PHP Zookeeper 包下载页：http://pecl.php.net/package/zookeeper 1wget http://pecl.php.net/get/zookeeper-0.5.0.tgz \b二、 环境安装 libZookeeper安装 12345678wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.13/zookeeper-3.4.13.tar.gztar zxvf zookeeper-3.4.13.tar.gzcd zookeeper-3.4.13/src/c./configure prefix=/usr/local/zookeeper-lib//libtool: warning: remember to run 'libtool --finish /usr/local/lib' make &amp;&amp; make install \bphp Zookeeper安装 12345678wget http://pecl.php.net/get/zookeeper-0.5.0.tgztar zxvf zookeeper-0.5.0.tgzcd zookeeper-0.5.0phpize./configure --with-php-config=/usr/bin/php-config --with-libzookeeper-dir=/usr/local/zookeeper-lib/make &amp;&amp; make install 三、shell安装脚本编写12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#!/bin/bash# Author: yuekang &lt;iyuekang AT gmail.com&gt;# Notes: 此脚本专用用于php安装zookeeper安装export PATH=/sbin:/bin:/usr/sbin:/usr/bin:/usr/local/sbin:/usr/local/binclearprintf &quot;######################################################################## zookeeper Extension Install shell ## For online use only ########################################################################&quot;# Check if user is root[ $(id -u) != '0' ] &amp;&amp; { echo &quot;${CFAILURE}Error: You must be root to run this script${CEND}&quot;; exit 1; }php_install_dir=&quot;/usr/local/php&quot;# Check PHPif [ -e &quot;${php_install_dir}/bin/phpize&quot; ]; then phpExtensionDir=$(${php_install_dir}/bin/php-config --extension-dir) PHP_detail_ver=$(${php_install_dir}/bin/php -r 'echo PHP_VERSION;') PHP_main_ver=${PHP_detail_ver%.*}fi# 安装zookeeper Lib库install_Zookeeper_lib() { src_url=&quot;http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.13/zookeeper-3.4.13.tar.gz&quot; &amp;&amp; Download_src tar zxvf zookeeper-3.4.13.tar.gz cd zookeeper-3.4.13/src/c ./configure prefix=/usr/local/zookeeper-lib make &amp;&amp; make install cd rm -r zookeeper-3.4.13.tar.gz &amp;&amp; rm -rf zookeeper-3.4.13}# 安装zookeeper扩展install_Zookeeper_extension() { PHP_extension=&quot;zookeeper&quot; src_url=&quot;http://pecl.php.net/get/zookeeper-0.5.0.tgz&quot; &amp;&amp; Download_src tar zxvf zookeeper-0.5.0.tgz cd zookeeper-0.5.0 ${php_install_dir}/bin/phpize ./configure --with-php-config=&quot;${php_install_dir}/bin/php-config&quot; --with-libzookeeper-dir=/usr/local/zookeeper-lib/ make &amp;&amp; make install # 加载so组件 echo &quot;extension=${PHP_extension}.so&quot; &gt; ${php_install_dir}/etc/php.d/${PHP_extension}.ini cd rm -r zookeeper-0.5.0.tgz &amp;&amp; rm -rf zookeeper-0.5.0}Download_src() { [ -s &quot;${src_url##*/}&quot; ] &amp;&amp; echo &quot;[${CMSG}${src_url##*/}${CEND}] found&quot; || { wget --limit-rate=10M -4 --tries=6 -c --no-check-certificate ${src_url}; sleep 1; } if [ ! -e &quot;${src_url##*/}&quot; ]; then echo &quot;${CFAILURE}Auto download failed! You can manually download ${src_url} into the src directory.${CEND}&quot; kill -9 $$ll fi}# Check succCheck_succ() { [ -f &quot;${phpExtensionDir}/${PHP_extension}.so&quot; ] &amp;&amp; { echo;echo &quot;${CSUCCESS}PHP ${PHP_extension} module installed successfully! ${CEND}&quot;; }}install_Zookeeper_libinstall_Zookeeper_extensionCheck_succ","link":"/2018/11/06/2018-11-06-php%E5%AE%89%E8%A3%85ZooKeeper/"},{"title":"nginx上部署nginx-json-log来监控网站上接口的详细数据","text":"业务上有这么一个需求，当接口之间产生的错误仅仅只能靠nginx errlog 来查看，但是具体的交互信息咱们看不到，这里就需要监控Content-Type: application/json; 这样的交互数据，以便于后期业务排查错误变得更加的方便。 开源库： fooinha/nginx-json-log 这是一个可以记录输出到多个渠道的nginx模块，支持输出到文件，syslog,kafka这些渠道 地址： 点我 jiaz/nginx-http-json-log","link":"/2018/11/12/2018-11-12-nginx%E4%B8%8A%E9%83%A8%E7%BD%B2nginx-json-log%E6%9D%A5%E7%9B%91%E6%8E%A7%E7%BD%91%E7%AB%99%E4%B8%8A%E6%8E%A5%E5%8F%A3%E7%9A%84%E8%AF%A6%E7%BB%86%E6%95%B0%E6%8D%AE/"},{"title":"从零编译nginx+lua+cjson模块的nginx服务实现日志全程监控","text":"我们中有这样的需求就是，当前端和后端通过接口通信以后，我们在日常排查中缺少跟踪接口返回信息和所有头部信息的跟踪，针对于这个需求我们采用nginx+lua+cjson的形式通过lua脚本 准备的模块 LuaJIT http://luajit.org/download/LuaJIT-2.0.5.tar.gz lua-nginx-module https://github.com/openresty/lua-nginx-module/archive/v0.10.9rc7.tar.gz ngx_devel_kit https://github.com/simpl/ngx_devel_kit/archive/v0.3.0.tar.gz lua-cjson https://www.kyne.com.au/~mark/software/download/lua-cjson-2.1.0.tar.gz nginx http://nginx.org/download/nginx-1.14.1.tar.gz 软件安装 LuaJit安装 1234567891011121314151617wget http://luajit.org/download/LuaJIT-2.0.5.tar.gztar -zxvf LuaJIT-2.0.5.tar.gzcd LuaJIT-2.0.5makemake install PREFIX=/usr/local/luajit# 环境变量必须配置！vi /etc/profile# 加入下面两个环境变量export LUAJIT_LIB=/usr/local/luajit/libexport LUAJIT_INC=/usr/local/luajit/include/luajit-2.0 ngx_devel_kit和lua-nginx-module 自己选择安装位置，最好公共目录,我放在/usr/local下 12345678910wget https://github.com/simpl/ngx_devel_kit/archive/v0.3.0.tar.gzwget https://github.com/openresty/lua-nginx-module/archive/v0.10.9rc7.tar.gztar -zxvf v0.3.0.tar.gztar -zxvf v0.10.9rc7.tar.gzcp -R lua-nginx-module/ /usr/local/cp -R ngx_devel_kit/ /usr/local/ 安装nginx编译nginx 12345678910111213141516171819202122wget http://nginx.org/download/nginx-1.14.1.tar.gztar -zxvf nginx-1.14.1.tar.gzcd nginx-1.14.1# 注：报错gcc需要安装，可以执行yum install -y gcc g++ gcc-c++#依赖报错，可以执行yum -y install zlib zlib-devel openssl openssl--devel pcre pcre-devel./configure --with-ld-opt=&quot;-Wl,-rpath,$LUAJIT_LIB&quot; --conf-path=/etc/nginx/nginx.conf --add-module=/usr/local/ngx_devel_kit --add-module=/usr/local/lua-nginx-modulemake -j 4 &amp;&amp; make install# 加载lua库echo &quot;/usr/local/luajit/lib&quot; &gt;&gt; /etc/ld.so.confldconfig lua-cjson安装 12345678910111213141516171819wget https://www.kyne.com.au/~mark/software/download/lua-cjson-2.1.0.tar.gztar zxvf lua-cjson-2.1.0.tar.gzcd lua-cjson-2.1.0vi Makefile# 修改\b前缀(路径后不要留空格！！)PREFIX = /usr/local/luajitLUA_INCLUDE_DIR = $(PREFIX)/include/luajit-2.0make install# lua中引用cjson库时必须指定位置package.path = &quot;/usr/local/luajit/mylua/?.lua;&quot;package.cpath = &quot;/usr/local/luajit/lib/lua/5.1/?.so;&quot;local cjson = require(&quot;cjson&quot;); 网站配置日志手机依旧依靠nginx log的形式我们针对于需要的内容进行收集和填充到日志中去，依赖原有的阿里云日志服务进行收集 定义日志格式 123456789101112131415161718192021222324log_format json_combined escape=json '{' '&quot;time_local&quot;:&quot;$time_local&quot;,' '&quot;remote_addr&quot;:&quot;$remote_addr&quot;,' '&quot;remote_user&quot;:&quot;$remote_user&quot;,' '&quot;request&quot;:&quot;$request&quot;,' '&quot;req_headers&quot;:&quot;$req_headers&quot;,' '&quot;status&quot;: &quot;$status&quot;,' '&quot;http_host&quot;: &quot;$http_host&quot;,' '&quot;body_bytes_sent&quot;:&quot;$body_bytes_sent&quot;,' '&quot;request_time&quot;:&quot;$request_time&quot;,' '&quot;http_referrer&quot;:&quot;$http_referer&quot;,' '&quot;content_type&quot;:&quot;$content_type&quot;,' '&quot;req_body&quot;:&quot;$req_body&quot;,' '&quot;resp_body&quot;:&quot;$resp_body&quot;,' '&quot;ua&quot;:&quot;$http_user_agent&quot;,' '&quot;cookie_u&quot;:&quot;$cookie_u&quot;,' '&quot;referer&quot;:&quot;$http_referer&quot;,' '&quot;xff&quot;:&quot;$http_x_forwarded_for&quot;,' '&quot;ups_status&quot;:&quot;$upstream_status&quot;,' '&quot;ups_addr&quot;:&quot;$upstream_addr&quot;,' '&quot;resp_content_type&quot;:&quot;$resp_content_type&quot;,' '&quot;ups_time&quot;:&quot;$upstream_response_time&quot;' '}'; 定义req_header和resp_body收集 123456789101112131415161718192021222324252627# 开启lua记录请求体lua_need_request_body on;set $resp_body &quot;&quot;;set $resp_content_type &quot;&quot;;set $req_body &quot;&quot;;set $req_headers &quot;&quot;;header_filter_by_lua ' package.path = &quot;/usr/local/luajit/mylua/?.lua;&quot; package.cpath = &quot;/usr/local/luajit/lib/lua/5.1/?.so;&quot; local cjson = require(&quot;cjson&quot;); local headers, err = ngx.req.get_headers() local json = {}; for k, v in pairs(headers) do json[k] = v; end ngx.var.req_headers = cjson.encode(json);';body_filter_by_lua ' ngx.var.resp_content_type = ngx.resp.get_headers()[&quot;Content-Type&quot;] local resp_body = ngx.arg[1] ngx.ctx.buffered = (ngx.ctx.buffered or &quot;&quot;) .. resp_body if ngx.arg[2] and string.find(ngx.var.resp_content_type, &quot;application/json&quot;) then ngx.var.resp_body = ngx.ctx.buffered ngx.var.req_body = ngx.var.request_body end'; odps收集表结构 12345678910111213141516171819202122CREATE TABLE `access_json` ( `ip` string, `remote_user` string, `req_headers` string, `status` bigint, `http_host` string, `body_bytes_sent` bigint, `request_time` string, `http_referer` string, `content_type` string, `req_body` string, `resp_body` string, `http_user_agent` string, `cookie_u` string, `http_x_forwarded_for` string, `upstream_status` string, `upstream_addr` string, `resp_content_type` string, `upstream_response_time` string, `request` string) PARTITIONED BY (dt string); AB压力测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 yum -y install httpd-tools[root@zookeeperslave2 ~]# ab -c 1000 -n 10000 -r http://192.168.1.169/aaaThis is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 192.168.1.169 (be patient)Completed 1000 requestsCompleted 2000 requestsCompleted 3000 requestsCompleted 4000 requestsCompleted 5000 requestsCompleted 6000 requestsCompleted 7000 requestsCompleted 8000 requestsCompleted 9000 requestsCompleted 10000 requestsFinished 10000 requestsServer Software: nginx/1.14.1Server Hostname: 192.168.1.169Server Port: 80Document Path: /aaaDocument Length: 17 bytesConcurrency Level: 1000Time taken for tests: 1.508 secondsComplete requests: 10000Failed requests: 0Write errors: 0Total transferred: 1660000 bytesHTML transferred: 170000 bytesRequests per second: 6632.41 [#/sec] (mean)Time per request: 150.775 [ms] (mean)Time per request: 0.151 [ms] (mean, across all concurrent requests)Transfer rate: 1075.18 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 0 52 169.9 18 1040Processing: 11 50 29.4 41 273Waiting: 0 48 29.3 39 270Total: 30 102 171.4 65 1292Percentage of the requests served within a certain time (ms) 50% 65 66% 73 75% 82 80% 90 90% 150 95% 156 98% 1059 99% 1065 100% 1292 (longest request) 问题集结 AIO找不到的问题 12./configure: no supported file AIO was foundCurrently file AIO is supported on FreeBSD 4.3+ and Linux 2.6.22+ only 安装开发者工具 1yum groupinstall 'Development Tools' 缺少libxml2/libxslt模块 12./configure: error: the HTTP XSLT module requires the libxml2/libxsltlibraries. You can either do not enable the module or install the libraries. 安装\b缺失库 12yum -y install libxml2 libxml2-devyum -y install libxslt-devel 缺少GD库 12./configure: error: the HTTP image filter module requires the GD library.You can either do not enable the module or install the libraries. 安装GD库 1yum -y install gd-devel 缺少ExtUtils 1./configure: error: perl module ExtUtils::Embed is required 安装ExtUtils 1yum -y install perl-devel perl-ExtUtils-Embed 缺少GeoIP库 12./configure: error: the GeoIP module requires the GeoIP library.You can either do not enable the module or install the library. 安装缺失库 1yum -y install GeoIP GeoIP-devel GeoIP-data 6、 缺少Google Perftools （编译环境我是不装这个的，从编译选线去除这个依赖就行） 12./configure: error: the Google perftools module requires the Google perftoolslibrary. You can either do not enable the module or install the library. 1234567891011121314151617181920212223242526# 安装libunwindwget http://download.savannah.gnu.org/releases/libunwind/libunwind-0.99-beta.tar.gztar zxvf libunwind-0.99-beta.tar.gzcd libunwind-0.99-beta./configuremakemake install# 安装google-perftoolswget https://github.com/gperftools/gperftools/releases/download/gperftools-2.5/gperftools-2.5.tar.gztar zxvf gperftools-2.5.tar.gzcd gperftools-2.5./configure --prefix=/usr/local/gperftoolsmake &amp;&amp; make installvi /etc/ld.so.conf.d/usr_local_lib.conf#加入/usr/local/libldconfig# 添加环境vi /etc/profileexport LD_PRELOAD=/usr/local/gperftools/lib/libtcmalloc.soexport HEAPPROFILE=/usr/bin/gzip 8.模块版本不对 1[emerg] module &quot;/usr/lib64/nginx/modules/ngx_http_geoip_module.so&quot; version 1012002 instead of 1...ip.conf:1 这个错误是因为之前nginx是yum安装的他的版本是1.12.*的 我这次安装的nginx是最新版本1.14.*的所以我需要对这个模块进行升级 1234567891011vi /etc/yum.repos.d/nginx.repo[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/7/$basearch/gpgcheck=0enabled=1yum remove nginx-mod*yum install nginx-module-*","link":"/2018/11/14/2018-11-14-%E4%BB%8E%E9%9B%B6%E7%BC%96%E8%AF%91nginx-lua-cjson%E6%A8%A1%E5%9D%97%E7%9A%84nginx%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0%E6%97%A5%E5%BF%97%E5%85%A8%E7%A8%8B%E7%9B%91%E6%8E%A7/"},{"title":"LDAP 分享","text":"轻型目录访问协议（英文：Lightweight Directory Access Protocol，缩写：LDAP）是一个开放的，中立的，工业标准的应用协议，通过IP协议提供访问控制和维护分布式信息的目录信息。OpenLDAP是轻型目录访问协议（Lightweight Directory Access Protocol，LDAP）的自由和开源的实现，在其OpenLDAP许可证下发行，并已经被包含在众多流行的Linux发行版中。 目录服务目录是一个为查询、浏览和搜索而优化的专业分布式数据库，它呈树状结构组织数据，就好象Linux/Unix系统中的文件目录一样。目录数据库和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据。所以目录天生是用来查询的，就好象它的名字一样。 LDAP特点 LDAP的结构用树来表示，而不是用表格。正因为这样，就不能用SQL语句了 LDAP可以很快地得到查询结果，不过在写方面，就慢得多 LDAP提供了静态数据的快速查询方式 Client/server模型，Server 用于存储数据，Client提供操作目录信息树的工具 这些工具可以将数据库的内容以文本格式（LDAP 数据交换格式，LDIF）呈现在您的面前 LDAP是一种开放Internet标准，LDAP协议是跨平台的Interent协议 LDAP组成形式 基本概念 Entry条目，也叫记录项，是LDAP中最基本的颗粒，就像字典中的词条，或者是数据库中的记录。通常对LDAP的添加、删除、更改、检索都是以条目为基本对象的。 DN 标识名（distinguished Name ，DN） 例如：cn=baby,ou=marketing,ou=people,dc=mydomain,dc=org 通过DN的层次型语法结构，可以方便地表示出条目在LDAP树中的位置，通常用于检索。 RDN 一般指dn逗号最左边的部分，如cn=baby。它与RootDN不同，RootDN通常与RootPW同时出现，特指管理LDAP中信息的最高权限用户。 Base DN LDAP目录树的最顶部就是根，也就是所谓的“Base DN”，如”dc=mydomain,dc=org”。 Attribute 每个条目都可以有很多属性（Attribute），比如常见的人都有姓名、地址、电话等属性。每个属性都有名称及对应的值，属性值可以有单个、多个，比如你有多个邮箱。属性不是随便定义的，需要符合一定的规则，而这个规则可以通过schema制定,在openLDAP中通过导入基础的schema才能导入用户的账户信息 属性 别名 语法 描述 值 commonName cn Directory String 姓名 sean surname sn Directory String 姓 Chow organizationalUnitName ou Directory String 单位名 Chow ObjectClass 属性不是随便定义的，需要符合一定的规则，而这个规则可以通过schema制定。ObjectClass是属性的集合，LDAP预想了很多人员组织机构中常见的对象，并将其封装成对象类。比如人员（person）含有姓（sn）、名（cn）、电话(telephoneNumber)、密码(userPassword)等属性，单位职工(organizationalPerson)是人员(person)的继承类，除了上述属性之外还含有职务（title）、邮政编码（postalCode）、通信地址(postalAddress)等属性。通过对象类可以方便的定义条目类型。每个条目可以直接继承多个对象类，这样就继承了各种属性。eNumber属性，因为employeeNumber是在inetOrgPerson中定义的。 Schema 对象类（ObjectClass）、属性类型（AttributeType）、语法（Syntax）分别约定了条目、属性、值。这些构成了模式(Schema)——对象类的集合。条目数据在导入时通常需要接受模式检查，它确保了目录中所有的条目数据结构都是一致的。 LDIF LDIF（LDAP Data Interchange Format，数据交换格式）是LDAP数据库信息的一种文本格式，用于数据的导入导出，每行都是“属性: 值”行界定冒号分隔属性-值对 12345678910111213141516dn: uid=root,ou=People,dc=ethercap,dc=comuid: rootcn: rootobjectClass: accountobjectClass: posixAccountobjectClass: topobjectClass: shadowAccountuserPassword: {crypt}$6$gNN9MrahZoiKSplA$2dGv8AIDmGNvwuCxI5LIC6Ub/pMwV0nvKnMoZL/ruagZautrmUQ96I2tjehR9hLt.emzhn/GG9C1dd5qoLHrB.shadowMin: 0shadowMax: 99999shadowWarning: 7loginShell: /bin/bashuidNumber: 0gidNumber: 0homeDirectory: /rootgecos: root 半小时快速搭建实战//安装三大应用，服务端，客户端，导出导入工具 yum install -y openldap-servers openldap-clients migrationtools //配置文件 cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG chown ldap. /var/lib/ldap/DB_CONFIG //启动服务 systemctl start slapd systemctl enable slapd //生成root密码 ╭─root@ykdev ~ ╰─# slappasswd New password: Re-enter new password: {SSHA}/UFZ8EehpMMtKiiAy+vxdxH6fObhaF3l //修改rootdn密码 cat chrootpw.ldif dn: olcDatabase={0}config,cn=config changetype: modify add: olcRootPW olcRootPW: {SSHA}/UFZ8EehpMMtKiiAy+vxdxH6fObhaF3l ldapadd -Y EXTERNAL -H ldapi:/// -f chrootpw.ldif //导出基础的Schema，这些 Schema 文件位于 /etc/openldap/schema/ 目录中，定义了我们以后创建的条目可以使用哪些属性 [root@localhost ~]# ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldif SASL/EXTERNAL authentication started SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth SASL SSF: 0 adding new entry &quot;cn=cosine,cn=schema,cn=config&quot; [root@localhost ~]# ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldif SASL/EXTERNAL authentication started SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth SASL SSF: 0 adding new entry &quot;cn=nis,cn=schema,cn=config&quot; [root@localhost ~]# ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif SASL/EXTERNAL authentication started SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth SASL SSF: 0 adding new entry &quot;cn=inetorgperson,cn=schema,cn=config&quot; //配置 LDAP 的顶级域 [root@proxy ldap]# cat chdomain.ldif dn: olcDatabase={1}monitor,cn=config changetype: modify replace: olcAccess olcAccess: {0}to * by dn.base=&quot;gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth&quot; read by dn.base=&quot;cn=Manager,dc=my-domain,dc=com&quot; read by * none dn: olcDatabase={2}hdb,cn=config changetype: modify replace: olcSuffix olcSuffix: dc=my-domain,dc=com dn: olcDatabase={2}hdb,cn=config changetype: modify replace: olcRootDN olcRootDN: cn=Manager,dc=my-domain,dc=com dn: olcDatabase={2}hdb,cn=config changetype: modify replace: olcRootPW olcRootPW: {SSHA}/UFZ8EehpMMtKiiAy+vxdxH6fObhaF3l dn: olcDatabase={2}hdb,cn=config changetype: modify add: olcAccess olcAccess: {0}to attrs=userPassword,shadowLastChange by dn=&quot;cn=Manager,dc=my-domain,dc=com&quot; write by anonymous auth by self write by * none olcAccess: {1}to dn.base=&quot;&quot; by * read olcAccess: {2}to * by dn=&quot;cn=Manager,dc=my-domain,dc=com&quot; write by * read [root@localhost ~]# ldapmodify -Y EXTERNAL -H ldapi:/// -f chdomain.ldif //导入基础组信息什么的 [root@proxy ldap]# cat base.ldif dn: dc=my-domain,dc=com dc: my-domain objectClass: top objectClass: domain dn: ou=People,dc=my-domain,dc=com ou: People objectClass: top objectClass: organizationalUnit dn: ou=Group,dc=my-domain,dc=com ou: Group objectClass: top objectClass: organizationalUnit ldapadd -x -D &quot;cn=Manager,dc=my-domain,dc=com&quot; -W -f base.ldif //导入用户信息 //修改域名基础信息 vi /usr/share/migrationtools/migrate_common.ph $DEFAULT_BASE = &quot;dc=my-domain,dc=com&quot;; [root@proxy ldap]# /usr/share/migrationtools/migrate_passwd.pl /etc/passwd passwd.ldif [root@proxy ldap]# /usr/share/migrationtools/migrate_group.pl /etc/group group.ldif [root@proxy ldap]# ldapadd -x -D cn=Manager,dc=my-domain,dc=com -W -f passwd.ldif [root@proxy ldap]# ldapadd -x -D cn=Manager,dc=my-domain,dc=com -W -f group.ldif //查看所有记录 [root@proxy ldap]# ldapsearch -x -b &quot;dc=my-domain,dc=com&quot; -H ldap://192.168.1.1","link":"/2018/11/28/2018-11-28-LDAP-%E5%88%86%E4%BA%AB/"},{"title":"Centos 端口转发管理","text":"在工作中经常会遇到vpc网络，内网所有机器通过唯一一台对外的proxy机器进行共享上网，这里记录一下\b如何做好端口转发和管理。 展示所有nat表规则 以编号标注 12345678910111213141516171819202122root@jumper:~# iptables -L -t nat --line-numberChain PREROUTING (policy ACCEPT)num target prot opt source destination1 DNAT tcp -- anywhere anywhere tcp dpt:EtherNet/IP-1 to:192.168.1.3:25382 DNAT tcp -- anywhere anywhere tcp dpt:ssh to:192.168.1.2:25383 DNAT tcp -- anywhere anywhere tcp dpt:7687 to:192.168.1.3:76874 DNAT tcp -- anywhere anywhere tcp dpt:dxspider to:192.168.1.3:8873Chain INPUT (policy ACCEPT)num target prot opt source destinationChain OUTPUT (policy ACCEPT)num target prot opt source destinationChain POSTROUTING (policy ACCEPT)num target prot opt source destination1 SNAT tcp -- anywhere newdev.my-domain.com tcp dpt:EtherNet/IP-1 to:192.168.1.12 SNAT tcp -- anywhere dev.my-domain.com tcp dpt:vnwk-prapi to:192.168.1.13 SNAT tcp -- anywhere dev.my-domain.com tcp dpt:ssh to:192.168.1.14 SNAT tcp -- anywhere newdev.my-domain.com tcp spt:7687 to:192.168.1.15 SNAT tcp -- anywhere newdev.my-domain.com tcp spt:dxspider to:192.168.1.16 SNAT all -- 192.168.1.0/24 anywhere to:192.168.1.1 删除其中一个规则 12345// 删除nat表PREROUTING中的第一个规则iptables -t nat -D PREROUTING 1// 删除nat表中POSTROUTING中的第一个规则iptables -t nat -D POSTROUTING 1 添加转发规则 12iptables -t nat -A PREROUTING -p tcp -m tcp --dport 2233 -j DNAT --to-destination 192.168.1.2:2538iptables -t nat -A POSTROUTING -d 192.168.1.2/32 -p tcp -m tcp --dport 2233 -j SNAT --to-source 192.168.1.1","link":"/2018/12/14/2018-12-14-Centos-%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91%E7%AE%A1%E7%90%86/"},{"title":"RabbitMQ 系统架构和通信过程","text":"MQ全称为Message Queue, 是一种分布式应用程序的的通信方法，它是消费-生产者模型的一个典型的代表，producer往消息队列中不断写入消息，而另一端consumer则可以读取或者订阅队列中的消息。RabbitMQ是MQ产品的典型代表，是一款基于AMQP协议可复用的企业消息系统。业务上，可以实现服务提供者和消费者之间的数据解耦，提供高可用性的消息传输机制，在实际生产中应用相当广泛。 RabbitMQ简介RabbitMQ是一个由Erlang开发的AMQP（AdvancedMessage Queue ）的开源实现，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 Rabbitmq系统最核心的组件是Exchange和Queue，下图是系统简单的示意图。Exchange和Queue是在rabbitmq Server AMQP 简介AMQP，即Advanced Message Queuing Protocol,一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。Erlang中的实现有 RabbitMQ等。 Message Broker与AMQP简介Message Broker是一种消息验证、传输、路由的架构模式，其设计目标主要应用于下面这些场景： 消息路由到一个或多个目的地 消息转化为其他的表现方式 执行消息的聚集、消息的分解，并将结果发送到他们的目的地，然后重新组合相应返回给消息用户 调用Web服务来检索数据 响应事件或错误 使用发布-订阅模式来提供内容或基于主题的消息路由 AMQP是Advanced Message QueuingProtocol的简称，它是一个面向消息中间件的开放式标准应用层协议。AMQP定义了这些特性： 消息方向 消息队列 消息路由（包括：点到点和发布-订阅模式） 可靠性 安全性 RabbitMQ就是以AMQP协议实现的一种中间件产品，它可以支持多种操作系统，多种编程语言，几乎可以覆盖所有主流的企业级技术平台。 Rabbitmq系统架构Rabbitmq系统最核心的组件是Exchange和Queue，下图是系统简单的示意图。Exchange和Queue是在rabbitmq server（又叫做broker）端，producer和consumer在应用端。 \b1. Producer 生产者2. Consumer 消费者3. Queue消息队列，提供了FIFO的处理机制，具有缓存消息的能力。rabbitmq中，队列消息可以设置为持久化，临时或者自动删除。 设置为持久化的队列，queue中的消息会在server本地硬盘存储一份，防止系统crash，数据丢失设置为临时队列，queue中的数据在系统重启之后就会丢失设置为自动删除的队列，当不存在用户连接到server，队列中的数据会被自动删除 ExchangeExchange类似于数据通信网络中的交换机，提供消息路由策略。rabbitmq中，producer不是通过信道直接将消息发送给queue，而是先发送给Exchange。一个Exchange可以和多个Queue进行绑定，producer在传递消息的时候，会传递一个ROUTING_KEY，Exchange会根据这个ROUTING_KEY按照特定的路由算法，将消息路由给指定的queue。和Queue一样，Exchange也可设置为持久化，临时或者自动删除。 Exchange有4种类型：direct(默认)，fanout, topic, 和headers，不同类型的Exchange转发消息的策略有所区别 4.1. Direct直接交换器，工作方式类似于单播，Exchange会将消息发送完全匹配ROUTING_KEY的Queue 4.2. fanout广播是式交换器，不管消息的ROUTING_KEY设置为什么，Exchange都会将消息转发给所有绑定的Queue。 4.3 topic主题交换器，工作方式类似于组播，Exchange会将消息转发和ROUTING_KEY匹配模式相同的所有队列，比如，ROUTING_KEY为user.stock的Message会转发给绑定匹配模式为 * .stock,user.stock， * . * 和#.user.stock.#的队列。（ * 表是匹配一个任意词组，#表示匹配0个或多个词组） 4.4. headers消息体的header匹配（ignore） Binding 所谓绑定就是将一个特定的 Exchange 和一个特定的 Queue 绑定起来。Exchange 和Queue的绑定可以是多对多的关系。 Virtual host 在rabbitmq server上可以创建多个虚拟的message broker，又叫做virtual hosts (vhosts)。每一个vhost本质上是一个mini-rabbitmq server，分别管理各自的exchange，和bindings。vhost相当于物理的server，可以为不同app提供边界隔离，使得应用安全的运行在不同的vhost实例上，相互之间不会干扰。producer和consumer连接rabbit server需要指定一个vhost。 通信过程假设P1和C1注册了相同的Broker，Exchange和Queue。P1发送的消息最终会被C1消费。基本的通信流程大概如下所示： P1生产消息，发送给服务器端的ExchangeExchange收到消息，根据ROUTINKEY，将消息转发给匹配的Queue1Queue1收到消息，将消息发送给订阅者C1C1收到消息，发送ACK给队列确认收到消息Queue1收到ACK，删除队列中缓存的此条消息 Consumer收到消息时需要显式的向rabbit broker发送basic.ack消息或者consumer订阅消息时设置auto_ack参数为true。在通信过程中，队列对ACK的处理有以下几种情况： 如果consumer接收了消息，发送ack,rabbitmq会删除队列中这个消息，发送另一条消息给consumer。如果cosumer接受了消息, 但在发送ack之前断开连接，rabbitmq会认为这条消息没有被deliver,在consumer在次连接的时候，这条消息会被redeliver。如果consumer接受了消息，但是程序中有bug,忘记了ack,rabbitmq不会重复发送消息。rabbitmq2.0.0和之后的版本支持consumer reject某条（类）消息，可以通过设置requeue参数中的reject为true达到目地，那么rabbitmq将会把消息发送给下一个注册的consumer。","link":"/2019/01/15/2019-01-15-RabbitMQ-%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%92%8C%E9%80%9A%E4%BF%A1%E8%BF%87%E7%A8%8B/"},{"title":"docker三大件之镜像学习","text":"操作系统分为内核和用户空间，，对于linux而言，内核启动后，会挂载root 文件系统为其提供用户空间支持。而Docker镜像（Image），就相当于是一个root文件系统。比如官方镜像ubuntu:18.04 就包含了完整的一套最小的root 文件系统。 Docker镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建后也不会被改变。 docker安装1 获取镜像Docker镜像仓库获取镜像的命令是docker pull。其格式为docker pull [选项] [Docker Registry 地址[:端口号/]仓库名[:标签]] 拉取","link":"/2019/01/16/2019-01-16-docker%E4%B8%89%E5%A4%A7%E4%BB%B6%E4%B9%8B%E9%95%9C%E5%83%8F%E5%AD%A6%E4%B9%A0/"},{"title":"kubernetes搭建","text":"搭建环境最快的方法就是参照官方稳定进行搭建：https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/ 一、 环境要求 一个或者多个兼容 deb 或者 rpm 软件包的操作系统，比如 Ubuntu 或者 CentOS 每台机器 2 GB 以上的内存，内存不足时应用会受限制,主节点上 2 CPU 以上核心 集群里所有的机器有完全的网络连接，公有网络或者私有网络都可以 docker 1.9版本以上 etcd 2.0版本以上 本次搭建测试环境 虚拟机三台分别是：Master 一个，Node 二个 二、 安装k8s 关闭swap和firewall 12345678910111213//临时关闭swapoff -a//永久关闭vi /etc/fstab//注释以下行# /dev/mapper/centos-swap swap//快捷执行方法sed -i '/ swap / s/^/#/' /etc/fstab//关闭防火墙service firewalld stop 安装docker 添加安装源 12yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum makecache 找不到执行(yum-config-manager)：yum -y install yum-utils 安装docker 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647yum install docker-ce -y//查看版本验证安装docker --versionDocker version 18.09.4, build d14af54266//开机启动systemctl start docker &amp; systemctl enable docker//验证容器是否正常docker run hello-worlddocker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.See 'docker run --help'.//说明docker没有启动，启动docker引擎service docker start//重新验证安装 下方为安装成功的情况docker run hello-worldUnable to find image 'hello-world:latest' locallylatest: Pulling from library/hello-world1b930d010525: Pull completeDigest: sha256:2557e3c07ed1e38f26e389462d03ed943586f744621577a99efb77324b0fe535Status: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ 安装 kubelet kubeadm kubectl 123456789101112131415161718192021cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# 将 SELinux 设置为 permissive 模式(将其禁用)setenforce 0sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/configyum install -y kubelet kubeadm kubectl --disableexcludes=kubernetessystemctl enable kubelet &amp;&amp; systemctl start kubelet 启动kuberlet 1systemctl enable kubelet &amp;&amp; systemctl start kubelet 下载官网编译好的二进制k8s包 进入github下载地址：https://github.com/kubernetes/kubernetes/releases","link":"/2019/04/07/2019-04-07-kubernetes%E6%90%AD%E5%BB%BA/"},{"title":"k8s关键术语和概念总结","text":"Kubernetes是一个全新的基于容器技术的分布式架构领先方案。这个方案虽然很新，但谷歌已经稳定运行了十几年以来大规模应用容器化技术的积累和升华的重要成功。运用K8s我们不仅能节省不少于30%的开发成本，同时可以将更多地经历放到业务本身，我们不必再费心于服务监控和故障处理模块的开发和开发复杂的服务治理框架，一切的一切它都为我们做好了。 总览为了更好地了解k8s我先从整体架构开始，了解一件事情先要总览，然后逐步了解每个细节的内容，逐步应用容器编排技术。 上面是k8s设计架构图，从图中可以看到Kubernetes主要由以下几个核心组件组成： etcd保存了整个集群的状态 apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制 controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上 kubelet负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理 Container runtime负责镜像管理以及Pod和容器的真正运行（CRI） kube-proxy负责为Service提供cluster内部的服务发现和负载均衡 官方还推荐一些其他组件： kube-dns负责为整个集群提供DNS服务 Ingress Controller为服务提供外网入口 Heapster提供资源监控 Dashboard提供GUI Federation提供跨可用区的集群 Fluentd-elasticsearch提供集群日志采集、存储与查询 K8s分层架构 核心层：Kubernetes最核心的功能，对外提供API构建高层的应用，对内提供插件式应用执行环境 应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS解析等） 管理层：系统度量（如基础设施、容器和网络的度量），自动化（如自动扩展、动态Provision等）以及策略管理（RBAC、Quota、PSP、NetworkPolicy等） 接口层：kubectl命令行工具、客户端SDK以及集群联邦 生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴 Kubernetes外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS应用、ChatOps等 Kubernetes内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等 Master Master是集群控制节点，每个K8s集群需要有一个Master节点来负责整个集群的管理和控制，基本上k8s所有的控制命令都是发给它的，它来负责具体的执行过程，Master节点通常会占据一个独立的x86服务器（或者一个虚拟机），正因为如此重要所有它挂掉了整个集群的所有控制命令都将失效，所以他就是军队的司令部大脑，正因为如此重要他就是集群的单点了，测试环境我们可以设置一个Master主机，生产环境我们一般会设置多个Master来达到高可用的目的，阿里云容器服务k8s已经为我们做到了高可用，它默认创建集群服务会为你创建三台主机来运行Mster，它的运行模式也是采用选举算法，这也就是为什么Master数量是偶数的，所以达到高可用至少3台主机以上的奇数个主机数量才能达到高可用的目的。 Mster运行着一下一组关键进程： kube-apiserver: 提供Rest接口的关键服务进程，是真个k8s里所有资源的增删改查操作的唯一入口，也是集群控制的入口进程。 kube-controller-manager： k8s所有资源对象的自动化控制中心，可以理解为资源对象的“内务大总管”。 kube-scheduler: 负责资源调度（Pod）的进程，相当于地铁的“调度中心”。 etcd: 主节点一般都会启动这个服务，主要提供所有资源对象数据都存在在里面，如果其中一台机pod节点发生故障或者未达到预期目标，k8s会读取etcd里面的数据进行重新资源的部署。 Node 除了Master, k8s集群里面其他机器一律称作为Node节点，Node节点和主节点一样可以使一台物理主机也可以是一台虚拟机。Node节点是k8s集群中的工作负载节点，每一台Node都会被Master分到一部分工作负载（docker容器），当其中某个Node节点宕机时，其上的工作负载还会被Master自动转移到其他节点上去。 每个Node节点上都运行着以下一组关键进程。 kubelet: 负责Pod对应的容器的创建、启停等任务，同时与Master节点密切协作，实现集群管理的基本功能。 kube-proxy:实现Kubernetes Service的通信与负载均衡机制的重要组件。 Docker Engine（docker）： Docker引擎负责本机的容器创建和管理工作 Node节点可以在运行期间动态添加到K8s急群众，前提是这个节点上已经正确钱庄、配置和启动了上述关键进程。一旦Node被纳入集群管理范围，kubelet会定时想Master节点汇报自身情况，这样Master可以获知每个Node的资源使用情况，并实现高效的负载均衡的资源调度策略。 而某个Node超过指定时间不上报信息时，会被Master判定为失联，Node的状态会被标记为不可用（Not Ready）,随后Master会出发工作负载大转移 的自动化迁移流程。 总结通过上面的内容就能够对k8s大致形态和规则有了相应的了解，也知道了k8s是由哪些关键进程组成的，他们的写作模式是什么？ k8s是如何达到高可用的目的，后续我会更多整理相关知识，继续深入研究k8s相关内容。","link":"/2019/04/08/2019-04-08-k8s%E5%85%B3%E9%94%AE%E6%9C%AF%E8%AF%AD%E5%92%8C%E6%A6%82%E5%BF%B5%E6%80%BB%E7%BB%93/"},{"title":"k8s部署方式整理","text":"是不会方式多种多样 MicroK8s部署 MicroK8s适合单机测试环境，友好的操作体验可以很轻松的上手k8s集群控制和开发。 1234567891011121314151617181920212223242526272829// MicroK8s 依赖 snapd工具需要第一个安装sudo yum install epel-releasesudo yum install snapdsudo systemctl enable --now snapd.socketsudo ln -s /var/lib/snapd/snap /snap//通过snap工具安装microk8ssudo snap install microk8s --classicsnap info microk8s// 启动集群sudo microk8s.start//停止集群sudo microk8s.stop//查看所有容器启动情况microk8s.kubectl get all --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGEdefault pod/nginx-7db9fccd9b-7klhs 0/1 ContainerCreating 0 76mdefault pod/nginx-7db9fccd9b-8zjwg 0/1 ContainerCreating 0 7//查看当前集群的编号和版本[root@k8smaster ~]# microk8s.kubectl get noNAME STATUS ROLES AGE VERSIONk8smaster Ready &lt;none&gt; 109m v1.14.0//监控当前所有容器工作状态watch microk8s.kubectl get all --all-namespaces 123//删除容器microk8s.kubectl delete deployment/nginxdeployment.extensions &quot;nginx&quot; deleted 以安装包的方式直接搭建etcd服务 etcd 服务是作为k8s集群的主数据库，用来存放所有的容器状态的主数据库。 123456789101112131415161718192021222324252627// 安装etcdyum install etcd// etcd配置文件, 默认监听在2379号端口vi /etc/etcd/etcd.conf//指定数据存放位置ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;//指定该节点名称ETCD_NAME=&quot;master&quot;//指定客户端监听url，对外提供服务的地址ETCD_LISTEN_CLIENT_URLS=&quot;http://localhost:2379&quot;//对外公告该客户端监听地址ETCD_ADVERTISE_CLIENT_URLS=&quot;http://localhost:2379&quot;// 启动服务systemctl daemon-reload// 启动服务systemctl enable etcd.servicesystemctl start etcd.service//验证etcd健康状态etcdctl -C http://localhost:2379 cluster-healthmember 8e9e05c52164694d is healthy: got healthy result from http://localhost:2379cluster is healthy k8s Mster 相关服务安装 接下来将是我们非常重要的服务，k8s它有三个主要的服务： kube-apiserver服务 kube-kube-controller-manager服务,依赖apiserver kube-scheduler服务,依赖apiserver 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061//三个服务都已经集成到kubernetes中了yum install kubernetes -y//配置kube-apiservervi /etc/kubernetes/apiserverKUBE_API_ADDRESS=&quot;--insecure-bind-address=0.0.0.0&quot; KUBE_ETCD_SERVERS=&quot;--etcd-servers=http://127.0.0.1:2379&quot; KUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot;KUBE_ADMISSION_CONTROL=&quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota&quot;KUBE_API_ARGS=&quot;--insecure-port=8000--service-cluster-ip-range=169.169.0.0/16--service-node-port-range=1-65535-logtostderr=false--log-dir=/var/log/kubernetes-v=2&quot;//配置kube-controller-managervi /etc/kubernetes/controller-managerKUBE_CONTROLLER_MANAGER_ARGS=&quot;--master=http://127.0.0.1:8000--logtostderr=false--v=2&quot; //配置kube-schedulervi /etc/kubernetes/schedulerKUBE_SCHEDULER_ARGS=&quot;-master=http://127.0.0.1:8000--logtostderr=false--log-dir=/var/log/kubernetes--v=2&quot; //k8s配置configvi /etc/kubernetes/configKUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot; KUBE_LOG_LEVEL=&quot;--v=0&quot;KUBE_ALLOW_PRIV=&quot;--allow-privileged=false&quot;KUBE_MASTER=&quot;--master=http://127.0.0.1:8000&quot;//启动k8s各个组件systemctl start kube-apiserver.servicesystemctl start kube-controller-manager.servicesystemctl start kube-scheduler.service//加入到系统服务中systemctl enable kube-apiserver.serviceCreated symlink from /etc/systemd/system/multi-user.target.wants/kube-apiserver.service to /usr/lib/systemd/system/kube-apiserver.service.systemctl enable kube-controller-manager.serviceCreated symlink from /etc/systemd/system/multi-user.target.wants/kube-controller-manager.service to /usr/lib/systemd/system/kube-controller-manager.service.systemctl enable kube-scheduler.serviceCreated symlink from /etc/systemd/system/multi-user.target.wants/kube-scheduler.service to /usr/lib/systemd/system/kube-scheduler.service. k8s Worker服务搭建 1234567891011121314//安装服务yum install kubernetes -y//k8s配置vi /etc/kubernetes/config//指定master地址位置KUBE_MASTER=&quot;--master=http://127.0.0.1:8000&quot;//启动服务systemctl enable kubelet.servicesystemctl enable kube-proxy.service//配置master节点地址export KUBERNETES_MASTER=http://centos-master:8080","link":"/2019/04/08/2019-04-08-k8s%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F%E6%95%B4%E7%90%86/"},{"title":"搭建ES服务","text":"前言Es ES 搭建123456789101112131415161718//添加官方源vi /etc/yum.repos.d/elasticsearch.repo//安装ES服务yum install --enablerepo=elasticsearch elasticsearch//服务启停 service方式sudo chkconfig --add elasticsearchsudo -i service elasticsearch startsudo -i service elasticsearch stop//systemctl方式sudo /bin/systemctl daemon-reloadsudo /bin/systemctl enable elasticsearch.servicesudo systemctl start elasticsearch.servicesudo systemctl stop elasticsearch.service Kibana 搭建123456789101112131415161718192021vi /etc/yum.repos.d/kibana.repo[kibana-7.x]name=Kibana repository for 7.x packagesbaseurl=https://artifacts.elastic.co/packages/7.x/yumgpgcheck=1gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearchenabled=1autorefresh=1type=rpm-md//添加服务sudo chkconfig --add kibanasudo -i service kibana startsudo -i service kibana stop//systemd管理sudo /bin/systemctl daemon-reloadsudo /bin/systemctl enable kibana.servicesudo systemctl start kibana.servicesudo systemctl stop kibana.service","link":"/2020/01/04/2020-01-04-%E6%90%AD%E5%BB%BAES%E6%9C%8D%E5%8A%A1/"},{"title":"为Hexo 的 md 文件统一重命名","text":"换用 Hexo 之后发现 _post 目录里面乱乱的，比如从 WordPress 中导入的中文标题文章的文件名会变成乱乱的字符串，看着很难受。所以搞了个改名的脚本来重命名文件。 重命名之后的格式为 PO文日期.文章标题.md，如果文件内有注明 urlname 的话就是 PO文日期.文章标题.urlname.md。 12345678910111213141516171819202122232425262728293031#!/bin/bash#保存系统默认的 IFSSAVEIFS=$IFS#更改 IFS 为换行（用于处理文件名含有空格的文件IFS=$'\\n'for filename in *.md; do #标题（不想替换空格的话就删除“s/ /_/g”。 title=$(grep &quot;title: &quot; $filename | head -1 | sed -e 's/title: //g; s#/##g;s/ /_/g') #发文日期 date=$(grep &quot;date: &quot; $filename | awk 'NR==1{printf $2}' ) #urlname link=$(grep &quot;urlname: &quot; $filename | head -1 | sed 's/urlname: //g' ) #新文件名 if [ -z &quot;$link&quot; ]; then newname=&quot;$date.$title.md&quot; else newname=&quot;$date.$title.$link.md&quot; fi #过滤掉名字正确的 if [ &quot;$filename&quot; != &quot;$newname&quot; ]; then #开始改名 echo &quot;Rename $filename to $newname&quot; mv $filename $newname fidoneecho done! 展示效果: 这样就舒服好多了。","link":"/2024/09/04/2024-09-04-%E4%B8%BAHexo-%E7%9A%84-md-%E6%96%87%E4%BB%B6%E7%BB%9F%E4%B8%80%E9%87%8D%E5%91%BD%E5%90%8D/"},{"title":"MySQL各模块的作用","text":"我们要学好mysql必须要了解其中都有哪些模块，并且对模块功能要非常清楚，举一反三知道其中原理。 下面是mysql的模块图 可以看到， MySQL 的架构共分为两层：Server 层和存储引擎层， Server 层负责建立连接、分析和执行 SQL。MySQL 大多数的核心功能模块都在这实现,主要包括连接器，查询缓存、解析器、预处理器、优化器、执行器等。另外，所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等。）都在 Server 层实现。 存储引擎层负责数据的存储和提取。支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。现在最常用的存储引擎是 InnoDB，从 MySQL 5.5 版本开始，InnoDB 成为了 MySQL 的默认存储引擎。我们常说的索引数据结构，就是由存储引擎层实现的，不同的存储引擎支持的索引类型也不相同，比如 InnoDB 支持索引类型是 B+树 ，且是默认使用，也就是说在数据表中创建的主键索引和二级索引默认使用的是 B+ 树索引。 1. 连接器 负责建立连接，权限验证 2.查询缓存 负责缓存查询出来的数据，通过查询语句作为key来进行match 一旦多次查询相同内容将会立刻返回内容。8.0以后就删除了这个功能，因为很鸡肋，频繁更新表都会导致缓存被清空。 3.解释器 负责对查询语句进行 词法分析和语法分析 词法分析 根据词法分析的结果，语法解析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法，如果没问题就会构建出 SQL 语法树，这样方便后面模块获取 SQL 类型、表名、字段名、 where 条件等等。 语法分析 根据词法分析的结果，语法解析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法，如果没问题就会构建出 SQL 语法树，这样方便后面模块获取 SQL 类型、表名、字段名、 where 条件等等。 如果这里分析出来语法不对就会报错 但是注意，表不存在或者字段不存在，并不是在解析器里做的，《MySQL 45 讲》说是在解析器做的，但是经过我和朋友看 MySQL 源码（5.7和8.0）得出结论是解析器只负责检查语法和构建语法树，但是不会去查表或者字段存不存在。 4. 预处理器 经过解析器后，接着就要进入执行 SQL 查询语句的流程了，每条SELECT 查询语句流程主要可以分为下面这三个阶段： prepare 阶段，也就是预处理阶段； optimize 阶段，也就是优化阶段； execute 阶段，也就是执行阶段； 预处理阶段 用来判断表是否存在，表字段是否存在检查 5.优化器 经过预处理阶段后，还需要为 SQL 查询语句先制定一个执行计划，这个工作交由「优化器」来完成的。 优化器主要负责将 SQL 查询语句的执行方案确定下来，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。 当然，我们本次的查询语句（select * from product where id = 1）很简单，就是选择使用主键索引。 要想知道优化器选择了哪个索引，我们可以在查询语句最前面加个 explain 命令，这样就会输出这条 SQL 语句的执行计划，然后执行计划中的 key 就表示执行过程中使用了哪个索引，比如下图的 key 为 PRIMARY 就是使用了主键索引。 6.执行器 经历完优化器后，就确定了执行方案，接下来 MySQL 就真正开始执行语句了，这个工作是由「执行器」完成的。在执行的过程中，执行器就会和存储引擎交互了，交互是以记录为单位的。","link":"/2024/09/06/MySQL%E5%90%84%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%9C%E7%94%A8/"}],"tags":[{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"面试题","slug":"面试题","link":"/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"开源库","slug":"开源库","link":"/tags/%E5%BC%80%E6%BA%90%E5%BA%93/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"安卓面试经验","slug":"安卓面试经验","link":"/tags/%E5%AE%89%E5%8D%93%E9%9D%A2%E8%AF%95%E7%BB%8F%E9%AA%8C/"},{"name":"PHP","slug":"PHP","link":"/tags/PHP/"},{"name":"Larvel","slug":"Larvel","link":"/tags/Larvel/"},{"name":"Web","slug":"Web","link":"/tags/Web/"},{"name":"Framwork","slug":"Framwork","link":"/tags/Framwork/"},{"name":"web","slug":"web","link":"/tags/web/"},{"name":"apidoc","slug":"apidoc","link":"/tags/apidoc/"},{"name":"博客感言","slug":"博客感言","link":"/tags/%E5%8D%9A%E5%AE%A2%E6%84%9F%E8%A8%80/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"mysql-router","slug":"mysql-router","link":"/tags/mysql-router/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Spring boot","slug":"Spring-boot","link":"/tags/Spring-boot/"},{"name":"framework","slug":"framework","link":"/tags/framework/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"php","slug":"php","link":"/tags/php/"},{"name":"spring-boot","slug":"spring-boot","link":"/tags/spring-boot/"},{"name":"shared-memory","slug":"shared-memory","link":"/tags/shared-memory/"},{"name":"php7","slug":"php7","link":"/tags/php7/"},{"name":"http","slug":"http","link":"/tags/http/"},{"name":"UserAgent","slug":"UserAgent","link":"/tags/UserAgent/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"PHP7","slug":"PHP7","link":"/tags/PHP7/"},{"name":"内存","slug":"内存","link":"/tags/%E5%86%85%E5%AD%98/"},{"name":"线程安全","slug":"线程安全","link":"/tags/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"},{"name":"垃圾回收","slug":"垃圾回收","link":"/tags/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"name":"array","slug":"array","link":"/tags/array/"},{"name":"IO","slug":"IO","link":"/tags/IO/"},{"name":"RPC","slug":"RPC","link":"/tags/RPC/"},{"name":"Yii","slug":"Yii","link":"/tags/Yii/"},{"name":"Mail","slug":"Mail","link":"/tags/Mail/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"CGI","slug":"CGI","link":"/tags/CGI/"},{"name":"FastCGI","slug":"FastCGI","link":"/tags/FastCGI/"},{"name":"LDAP","slug":"LDAP","link":"/tags/LDAP/"},{"name":"CentOS","slug":"CentOS","link":"/tags/CentOS/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"负载均衡","slug":"负载均衡","link":"/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"反向代理","slug":"反向代理","link":"/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"},{"name":"堡垒机","slug":"堡垒机","link":"/tags/%E5%A0%A1%E5%9E%92%E6%9C%BA/"},{"name":"jumperserver","slug":"jumperserver","link":"/tags/jumperserver/"},{"name":"运维","slug":"运维","link":"/tags/%E8%BF%90%E7%BB%B4/"},{"name":"saltStack","slug":"saltStack","link":"/tags/saltStack/"},{"name":"Zend虚拟机","slug":"Zend虚拟机","link":"/tags/Zend%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"django","slug":"django","link":"/tags/django/"},{"name":"HAProxy","slug":"HAProxy","link":"/tags/HAProxy/"},{"name":"KeepAlived","slug":"KeepAlived","link":"/tags/KeepAlived/"},{"name":"keepalived","slug":"keepalived","link":"/tags/keepalived/"},{"name":"高可用","slug":"高可用","link":"/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"OpenLdap","slug":"OpenLdap","link":"/tags/OpenLdap/"},{"name":"Centos","slug":"Centos","link":"/tags/Centos/"},{"name":"ZooKeeper","slug":"ZooKeeper","link":"/tags/ZooKeeper/"},{"name":"zookeeper","slug":"zookeeper","link":"/tags/zookeeper/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"log","slug":"log","link":"/tags/log/"},{"name":"监控","slug":"监控","link":"/tags/%E7%9B%91%E6%8E%A7/"},{"name":"lua","slug":"lua","link":"/tags/lua/"},{"name":"iptables","slug":"iptables","link":"/tags/iptables/"},{"name":"NAT","slug":"NAT","link":"/tags/NAT/"},{"name":"Rabbitmq","slug":"Rabbitmq","link":"/tags/Rabbitmq/"},{"name":"Queue","slug":"Queue","link":"/tags/Queue/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"镜像","slug":"镜像","link":"/tags/%E9%95%9C%E5%83%8F/"},{"name":"容器","slug":"容器","link":"/tags/%E5%AE%B9%E5%99%A8/"},{"name":"k8s","slug":"k8s","link":"/tags/k8s/"},{"name":"kubernetes","slug":"kubernetes","link":"/tags/kubernetes/"},{"name":"容器化","slug":"容器化","link":"/tags/%E5%AE%B9%E5%99%A8%E5%8C%96/"},{"name":"部署","slug":"部署","link":"/tags/%E9%83%A8%E7%BD%B2/"},{"name":"ES","slug":"ES","link":"/tags/ES/"},{"name":"服务","slug":"服务","link":"/tags/%E6%9C%8D%E5%8A%A1/"},{"name":"搜索服务","slug":"搜索服务","link":"/tags/%E6%90%9C%E7%B4%A2%E6%9C%8D%E5%8A%A1/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"rename","slug":"rename","link":"/tags/rename/"}],"categories":[]}